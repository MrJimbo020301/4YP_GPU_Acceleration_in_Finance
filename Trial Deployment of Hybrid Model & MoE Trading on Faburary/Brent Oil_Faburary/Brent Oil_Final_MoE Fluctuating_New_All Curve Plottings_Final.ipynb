{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "\n",
    "# For final zoom-in diagrams\n",
    "import matplotlib.dates as mdates\n",
    "from matplotlib.lines import Line2D\n",
    "\n",
    "############################################\n",
    "# 1. GLOBAL SETTINGS\n",
    "############################################\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "features = [\"Price\", \"Open\", \"High\", \"Low\"]\n",
    "WINDOW_SIZE = 35\n",
    "NUM_EPOCHS = 1500\n",
    "BEST_MODELS_DIR = \".\"  # directory with .pt/.pkl model files\n",
    "\n",
    "############################################\n",
    "# 2. Basic Data Preprocessing\n",
    "############################################\n",
    "def load_and_scale_data(train_csv, complete_csv):\n",
    "    df_trainval = pd.read_csv(train_csv)\n",
    "    df_trainval[\"Date\"] = pd.to_datetime(df_trainval[\"Date\"], errors=\"coerce\")\n",
    "    for col in [\"Vol.\", \"Change %\"]:\n",
    "        if col in df_trainval.columns:\n",
    "            df_trainval.drop(columns=[col], errors=\"ignore\", inplace=True)\n",
    "\n",
    "    for c in features:\n",
    "        if c not in df_trainval.columns:\n",
    "            df_trainval[c] = np.nan\n",
    "        else:\n",
    "            df_trainval[c] = df_trainval[c].astype(str).str.replace(\",\", \"\", regex=True)\n",
    "            df_trainval[c] = pd.to_numeric(df_trainval[c], errors=\"coerce\")\n",
    "\n",
    "    df_trainval.sort_values(\"Date\", inplace=True)\n",
    "    df_trainval.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    train_cutoff = pd.to_datetime(\"2024-08-01\")\n",
    "    val_cutoff   = pd.to_datetime(\"2024-12-30\")\n",
    "    test_cutoff  = pd.to_datetime(\"2025-01-01\")\n",
    "\n",
    "    df_train = df_trainval[df_trainval[\"Date\"] < train_cutoff].copy()\n",
    "    df_val   = df_trainval[(df_trainval[\"Date\"] >= train_cutoff) & (df_trainval[\"Date\"] <= val_cutoff)].copy()\n",
    "    df_test  = df_trainval[df_trainval[\"Date\"] >= test_cutoff].copy()\n",
    "\n",
    "    df_train_nonan = df_train.dropna(subset=features)\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(df_train_nonan[features])\n",
    "\n",
    "    df_train_scaled = df_train.copy()\n",
    "    if not df_train_nonan.empty:\n",
    "        df_train_scaled.loc[df_train_nonan.index, features] = scaler.transform(df_train_nonan[features])\n",
    "\n",
    "    df_val_scaled = df_val.copy()\n",
    "    val_no_nan = df_val_scaled.dropna(subset=features)\n",
    "    if not val_no_nan.empty:\n",
    "        df_val_scaled.loc[val_no_nan.index, features] = scaler.transform(val_no_nan[features])\n",
    "\n",
    "    df_test_scaled = df_test.copy()\n",
    "    train_mins = df_train_nonan[features].min()\n",
    "    df_test_filled = df_test_scaled[features].fillna(train_mins)\n",
    "    df_test_scaled.loc[:, features] = scaler.transform(df_test_filled)\n",
    "\n",
    "    df_scaled = pd.concat([df_train_scaled, df_val_scaled, df_test_scaled], ignore_index=True)\n",
    "\n",
    "    # Load complete CSV for final rolling\n",
    "    df_complete = pd.read_csv(complete_csv)\n",
    "    df_complete[\"Date\"] = pd.to_datetime(df_complete[\"Date\"], errors=\"coerce\")\n",
    "    for c in [\"Vol.\", \"Change %\"]:\n",
    "        if c in df_complete.columns:\n",
    "            df_complete.drop(columns=[c], inplace=True)\n",
    "    for f in features:\n",
    "        df_complete[f] = df_complete[f].astype(str).str.replace(\",\", \"\", regex=True).astype(float)\n",
    "    df_complete.sort_values(\"Date\", inplace=True)\n",
    "    df_complete.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return df_scaled, df_complete, scaler\n",
    "\n",
    "############################################\n",
    "# 3. Utility: Sequence & Slices\n",
    "############################################\n",
    "def make_sequences(df_subset, window=35):\n",
    "    arr = df_subset[features].values\n",
    "    dts = df_subset[\"Date\"].values\n",
    "    X_list, y_list, date_list = [], [], []\n",
    "    for i in range(window, len(arr)):\n",
    "        X_window = arr[i - window : i]\n",
    "        y_target = arr[i]\n",
    "        X_list.append(X_window)\n",
    "        y_list.append(y_target)\n",
    "        date_list.append(dts[i])\n",
    "    return np.array(X_list), np.array(y_list), np.array(date_list)\n",
    "\n",
    "############################################\n",
    "# 4. Model Definitions\n",
    "############################################\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_type=\"LSTM\", window_width=35):\n",
    "        super().__init__()\n",
    "        self.model_type = model_type\n",
    "\n",
    "        if model_type == \"CNN\":\n",
    "            self.conv1 = nn.Conv1d(4, 64, 3)\n",
    "            self.conv2 = nn.Conv1d(64, 128, 3)\n",
    "            with torch.no_grad():\n",
    "                dummy = torch.zeros(1, 4, window_width)\n",
    "                outdummy = self.conv2(F.relu(self.conv1(dummy)))\n",
    "                conv_output_size = outdummy.shape[1]*outdummy.shape[2]\n",
    "            self.fc = nn.Linear(conv_output_size, 4)\n",
    "\n",
    "        elif model_type == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(4, 128, num_layers=2, batch_first=True, dropout=0.05)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "\n",
    "        elif model_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(4, 128, num_layers=2, batch_first=True, dropout=0.05)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "\n",
    "        elif model_type == \"RNN\":\n",
    "            self.rnn = nn.RNN(4, 128, num_layers=2, nonlinearity=\"relu\", batch_first=True, dropout=0.05)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "\n",
    "        elif model_type == \"EnhancedLSTM\":\n",
    "            self.rnn = nn.LSTM(4, 128, num_layers=3, batch_first=True, dropout=0.1)\n",
    "            self.bn  = nn.BatchNorm1d(128)\n",
    "            self.dropout = nn.Dropout(0.1)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "\n",
    "        elif model_type == \"Transformer\":\n",
    "            self.input_linear = nn.Linear(4, 128)\n",
    "            encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=8, dropout=0.05)\n",
    "            self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=3)\n",
    "            self.fc = nn.Linear(128,4)\n",
    "\n",
    "        elif model_type in [\"N-BEATS\",\"N-HITS\"]:\n",
    "            self.input_size= window_width*4\n",
    "            self.blocks= nn.ModuleList([nn.Sequential(\n",
    "                nn.Linear(self.input_size,128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128,128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128,4)\n",
    "            ) for _ in range(3)])\n",
    "        else:\n",
    "            raise ValueError(f\"Invalid model_type: {model_type}\")\n",
    "\n",
    "    def forward(self, x):\n",
    "        if self.model_type == \"CNN\":\n",
    "            x = x.permute(0,2,1)\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = x.view(x.size(0), -1)\n",
    "            return self.fc(x)\n",
    "\n",
    "        elif self.model_type in [\"LSTM\",\"GRU\",\"RNN\"]:\n",
    "            out, _ = self.rnn(x)\n",
    "            out = out[:,-1,:]\n",
    "            return self.fc(out)\n",
    "\n",
    "        elif self.model_type == \"EnhancedLSTM\":\n",
    "            out, _= self.rnn(x)\n",
    "            out = out[:,-1,:]\n",
    "            out = self.bn(out)\n",
    "            out = self.dropout(out)\n",
    "            return self.fc(out)\n",
    "\n",
    "        elif self.model_type == \"Transformer\":\n",
    "            x = self.input_linear(x)\n",
    "            x = x.permute(1,0,2)\n",
    "            x = self.transformer_encoder(x)\n",
    "            x = x[-1,:,:]\n",
    "            return self.fc(x)\n",
    "\n",
    "        elif self.model_type in [\"N-BEATS\",\"N-HITS\"]:\n",
    "            xflat= x.reshape(x.size(0), -1)\n",
    "            forecast=0\n",
    "            for block in self.blocks:\n",
    "                forecast += block(xflat)\n",
    "            return forecast\n",
    "\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type\")\n",
    "\n",
    "############################################\n",
    "# 5. Model Loading (No training)\n",
    "############################################\n",
    "class SklearnWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model= model\n",
    "    def forward(self, x):\n",
    "        arr= x.cpu().numpy().reshape(1,-1)\n",
    "        pred= self.model.predict(arr)\n",
    "        return torch.from_numpy(pred).float().to(x.device)\n",
    "    def eval(self):\n",
    "        pass\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "def load_torch_model(model_type, window_size, model_save_name):\n",
    "    if not os.path.exists(model_save_name):\n",
    "        raise FileNotFoundError(f\"File not found: {model_save_name}\")\n",
    "    print(f\"[PyTorch] Loading existing {model_type} from {model_save_name}\")\n",
    "    net = BaseModel(model_type, window_size).to(device)\n",
    "    net.load_state_dict(torch.load(model_save_name, map_location=device))\n",
    "    net.eval()\n",
    "    return net\n",
    "\n",
    "def load_sklearn_model(model_type, model_save_name):\n",
    "    if not os.path.exists(model_save_name):\n",
    "        raise FileNotFoundError(f\"File not found: {model_save_name}\")\n",
    "    print(f\"[sklearn] Loading {model_type} => {model_save_name}\")\n",
    "    loaded= joblib.load(model_save_name)\n",
    "    return SklearnWrapper(loaded)\n",
    "\n",
    "############################################\n",
    "# 6. Forecasting utilities\n",
    "############################################\n",
    "def get_latest_window(df_actual, current_date, window=35, scaler=None):\n",
    "    mask= df_actual[\"Date\"]< current_date\n",
    "    df_sub= df_actual.loc[mask].copy()\n",
    "    df_sub.sort_values(\"Date\", inplace=True)\n",
    "    if len(df_sub)< window:\n",
    "        return None\n",
    "    df_sub[features]= df_sub[features].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    arr= scaler.transform(df_sub[features].iloc[-window:].values)\n",
    "    return arr\n",
    "\n",
    "def forecast_n_days_from_date(model, df_actual, start_date, window=35, horizon=30,\n",
    "                              device=None, scaler=None, noise_std=0.05):\n",
    "    \"\"\"\n",
    "    Full-blind forecast with random noise each day.\n",
    "    \"\"\"\n",
    "    def add_noise_4d(pred_unscaled, std=0.005):\n",
    "        noise= np.random.normal(0.0, std, size=pred_unscaled.shape)\n",
    "        return np.clip(pred_unscaled+ noise, a_min=0, a_max=None)\n",
    "\n",
    "    arr_window= get_latest_window(df_actual, start_date, window, scaler)\n",
    "    if arr_window is None:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    rolling_buffer= np.copy(arr_window)\n",
    "    forecast_records=[]\n",
    "    current_date= pd.to_datetime(start_date)\n",
    "\n",
    "    for i in range(horizon):\n",
    "        X_input= torch.tensor(rolling_buffer,dtype=torch.float).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred_scaled= model(X_input).cpu().numpy()[0]\n",
    "        pred_unscaled= scaler.inverse_transform(pred_scaled.reshape(1,-1))[0]\n",
    "        pred_noisy= add_noise_4d(pred_unscaled, noise_std)\n",
    "\n",
    "        dayx= current_date+ pd.Timedelta(days=i)\n",
    "        forecast_records.append({\n",
    "            \"ForecastDate\": dayx,\n",
    "            \"Pred_Price_unscaled\": pred_noisy[0],\n",
    "            \"Pred_Open_unscaled\":  pred_noisy[1],\n",
    "            \"Pred_High_unscaled\":  pred_noisy[2],\n",
    "            \"Pred_Low_unscaled\":   pred_noisy[3]\n",
    "        })\n",
    "\n",
    "        # shift rolling buffer\n",
    "        pred_noisy_scaled= scaler.transform(pred_noisy.reshape(1,-1))[0]\n",
    "        rolling_buffer= np.vstack([rolling_buffer[1:], pred_noisy_scaled.reshape(1,-1)])\n",
    "\n",
    "    return pd.DataFrame(forecast_records)\n",
    "\n",
    "############################################\n",
    "# 7. Rolling approach (LOAD only)\n",
    "############################################\n",
    "def plot_daily_two_charts(day_i, horizon_days, daily_fcst_dict, df_actual):\n",
    "    \"\"\"\n",
    "    Creates 2 plots for the given day_i:\n",
    "      1) Joint Diagram up to day_i + horizon_days\n",
    "      2) Zoomed diagram from day_i to day_i + horizon_days\n",
    "    \"\"\"\n",
    "    df_sorted= df_actual.copy()\n",
    "    df_sorted.sort_values(\"Date\", inplace=True)\n",
    "    day_end= day_i+ pd.Timedelta(days= horizon_days -1)\n",
    "\n",
    "    mask= (df_sorted[\"Date\"]<= day_end)\n",
    "    df_plot= df_sorted.loc[mask].copy()\n",
    "\n",
    "    # 1) Joint Diagram\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(df_plot[\"Date\"], df_plot[\"Price\"], color=\"black\", label=\"Actual Price\")\n",
    "\n",
    "    color_map= {\n",
    "        \"LSTM\": \"red\",\n",
    "        \"GRU\": \"blue\",\n",
    "        \"RNN\": \"green\",\n",
    "        \"CNN\": \"orange\",\n",
    "        \"EnhancedLSTM\": \"magenta\",\n",
    "        \"Transformer\": \"cyan\",\n",
    "        \"N-BEATS\": \"brown\",\n",
    "        \"N-HITS\": \"pink\",\n",
    "        \"SVM\": \"olive\",\n",
    "        \"GPR\": \"teal\",\n",
    "        \"Boost\": \"purple\"\n",
    "    }\n",
    "    for mname, fcdf in daily_fcst_dict.items():\n",
    "        sub= fcdf[fcdf[\"ForecastDate\"]<= day_end].copy()\n",
    "        if not sub.empty:\n",
    "            plt.plot(sub[\"ForecastDate\"], sub[\"Pred_Price_unscaled\"],\n",
    "                     color=color_map.get(mname,\"gray\"), linestyle=\"--\", label=f\"{mname} Forecast\")\n",
    "\n",
    "    plt.title(f\"Day {day_i.date()} - Joint Diagram (up to {day_end.date()}) of Brent Oil Futures \")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend(prop={\"size\":7})\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # 2) Zoom-In\n",
    "    plt.figure(figsize=(12,5))\n",
    "    maskz= (df_plot[\"Date\"]>= day_i)&(df_plot[\"Date\"]<= day_end)\n",
    "    df_zoom= df_plot.loc[maskz].copy()\n",
    "    if not df_zoom.empty:\n",
    "        plt.plot(df_zoom[\"Date\"], df_zoom[\"Price\"], color=\"black\", label=\"Actual Price\")\n",
    "    for mname, fcdf in daily_fcst_dict.items():\n",
    "        sub= fcdf[(fcdf[\"ForecastDate\"]>=day_i)&(fcdf[\"ForecastDate\"]<=day_end)]\n",
    "        if not sub.empty:\n",
    "            plt.plot(sub[\"ForecastDate\"], sub[\"Pred_Price_unscaled\"],\n",
    "                     color=color_map.get(mname,\"gray\"), linestyle=\"--\", label=f\"{mname} Forecast\")\n",
    "\n",
    "    plt.title(f\"Day {day_i.date()} - Zoom-In Forecast ({day_i.date()} to {day_end.date()}) of Brent Oil Futures \")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend(prop={\"size\":7})\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def rolling_train_validate_predict_moe(\n",
    "    df_full,\n",
    "    scaler_obj,\n",
    "    model_types,\n",
    "    start_train_cutoff=pd.to_datetime(\"2024-08-01\"),\n",
    "    start_val_cutoff=pd.to_datetime(\"2024-12-30\"),\n",
    "    start_pred=pd.to_datetime(\"2025-01-01\"),\n",
    "    end_pred=pd.to_datetime(\"2025-02-01\"),\n",
    "    horizon_days=30,\n",
    "    do_daily_plots=True\n",
    "):\n",
    "    \"\"\"\n",
    "    Loads each model from pre-saved files for each day in [start_pred..end_pred],\n",
    "    and produces a forecast with optional daily plots *only* on the final rolling day.\n",
    "    \"\"\"\n",
    "    df_sorted= df_full.copy()\n",
    "    df_sorted.sort_values(\"Date\", inplace=True)\n",
    "\n",
    "    df_scaled_all= df_sorted.copy()\n",
    "    df_scaled_all[features]= df_scaled_all[features].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "    df_scaled_all[features]= scaler_obj.transform(df_scaled_all[features])\n",
    "\n",
    "    date_range= pd.date_range(start_pred, end_pred, freq=\"D\")\n",
    "    all_records= []\n",
    "\n",
    "    for i, day_i in enumerate(date_range):\n",
    "        train_cutoff_i= start_train_cutoff + pd.Timedelta(days=i)\n",
    "        val_cutoff_i  = start_val_cutoff   + pd.Timedelta(days=i)\n",
    "\n",
    "        print(f\"\\n=== Rolling Day {day_i.date()} ===\")\n",
    "        print(f\"  Loading models for cutoff {train_cutoff_i.date()} / {val_cutoff_i.date()}\")\n",
    "        print(f\"  Forecast next {horizon_days} days from {day_i.date()} with noise\")\n",
    "\n",
    "        # 1) Load each model from file\n",
    "        model_dict= {}\n",
    "        for mt in model_types:\n",
    "            out_file= f\"best_{mt}_{day_i.strftime('%Y-%m-%d')}_V1\"\n",
    "            if mt in [\"SVM\",\"GPR\",\"Boost\"]:\n",
    "                out_file += \".pkl\"\n",
    "                net= load_sklearn_model(mt, os.path.join(BEST_MODELS_DIR, out_file))\n",
    "            else:\n",
    "                out_file += \".pt\"\n",
    "                net= load_torch_model(mt, WINDOW_SIZE, os.path.join(BEST_MODELS_DIR, out_file))\n",
    "            model_dict[mt]= net\n",
    "\n",
    "        # 2) Forecast\n",
    "        daily_fcst_dict= {}\n",
    "        for mt, net in model_dict.items():\n",
    "            df_fc= forecast_n_days_from_date(\n",
    "                model= net,\n",
    "                df_actual= df_sorted,  # unscaled\n",
    "                start_date= day_i,\n",
    "                window= WINDOW_SIZE,\n",
    "                horizon= horizon_days,\n",
    "                device= device,\n",
    "                scaler= scaler_obj,\n",
    "                noise_std=0.05\n",
    "            )\n",
    "            if not df_fc.empty:\n",
    "                df_fc[\"BaseDate\"]= day_i\n",
    "                df_fc[\"Model\"]= mt\n",
    "                daily_fcst_dict[mt]= df_fc\n",
    "                all_records.append(df_fc)\n",
    "            else:\n",
    "                daily_fcst_dict[mt]= pd.DataFrame()\n",
    "\n",
    "        # see actual\n",
    "        row_actual= df_sorted[df_sorted[\"Date\"]== day_i]\n",
    "        if not row_actual.empty:\n",
    "            print(f\"  Actual price: {row_actual['Price'].values[0]:.4f}\")\n",
    "\n",
    "        # 3) Only plot daily diagrams on the *final* rolling day\n",
    "        if do_daily_plots and (day_i == date_range[-1]):\n",
    "            plot_daily_two_charts(day_i, horizon_days, daily_fcst_dict, df_sorted)\n",
    "\n",
    "    df_all = pd.concat(all_records, ignore_index=True) if all_records else pd.DataFrame()\n",
    "    df_all.sort_values([\"Model\",\"BaseDate\",\"ForecastDate\"], inplace=True)\n",
    "    return df_all\n",
    "\n",
    "############################################\n",
    "# 8. Final Rolling Forecast Plot\n",
    "############################################\n",
    "def plot_final_rolling_fc(final_rolling_fcst, df_actual, from_d, to_d):\n",
    "    if final_rolling_fcst.empty:\n",
    "        print(\"No final rolling forecast data. Exiting.\")\n",
    "        return\n",
    "\n",
    "    df_act= df_actual.copy()\n",
    "    df_act.sort_values(\"Date\", inplace=True)\n",
    "    mask= (df_act[\"Date\"]>= from_d)&(df_act[\"Date\"]<= to_d)\n",
    "    df_a= df_act[mask].copy()\n",
    "\n",
    "    plt.figure(figsize=(12,5))\n",
    "    plt.plot(df_a[\"Date\"], df_a[\"Price\"], color=\"black\", label=\"ActualPrice\")\n",
    "\n",
    "    color_map= {\n",
    "        \"LSTM\": \"red\",\n",
    "        \"GRU\": \"blue\",\n",
    "        \"RNN\": \"green\",\n",
    "        \"CNN\": \"orange\",\n",
    "        \"EnhancedLSTM\": \"magenta\",\n",
    "        \"Transformer\": \"cyan\",\n",
    "        \"N-BEATS\": \"brown\",\n",
    "        \"N-HITS\": \"pink\",\n",
    "        \"SVM\": \"olive\",\n",
    "        \"GPR\": \"teal\",\n",
    "        \"Boost\": \"purple\"\n",
    "    }\n",
    "    for m in final_rolling_fcst[\"Model\"].unique():\n",
    "        df_m= final_rolling_fcst[final_rolling_fcst[\"Model\"]== m].copy()\n",
    "        df_m= df_m[(df_m[\"ForecastDate\"]>=from_d)&(df_m[\"ForecastDate\"]<= to_d)]\n",
    "        if not df_m.empty:\n",
    "            plt.plot(df_m[\"ForecastDate\"], df_m[\"Pred_Price_unscaled\"],\n",
    "                     color=color_map.get(m,\"gray\"), linestyle=\"--\", label=f\"{m} Forecast\")\n",
    "\n",
    "    plt.title(f\"Rolling Forecast from {from_d.date()} to {to_d.date()} of Brent Oil Futures \")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.legend(prop={\"size\":7})\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "############################################\n",
    "# 9. Helper functions for picking base dates\n",
    "############################################\n",
    "def pick_every_10th_base_dates(base_dates):\n",
    "    if len(base_dates)==0:\n",
    "        return []\n",
    "    sorted_bases = sorted(base_dates)\n",
    "    chosen = []\n",
    "    first_bd = sorted_bases[0]\n",
    "    for bd in sorted_bases:\n",
    "        day_diff = (bd - first_bd).days\n",
    "        if day_diff % 10 == 0:\n",
    "            chosen.append(bd)\n",
    "    # ensure final base date is included\n",
    "    if sorted_bases[-1] not in chosen:\n",
    "        chosen.append(sorted_bases[-1])\n",
    "    return sorted(chosen)\n",
    "\n",
    "def pick_every_5th_base_dates(base_dates):\n",
    "    \"\"\"\n",
    "    Similar logic, but for every 5th date difference from the first base date.\n",
    "    \"\"\"\n",
    "    if len(base_dates)==0:\n",
    "        return []\n",
    "    sorted_bases = sorted(base_dates)\n",
    "    chosen = []\n",
    "    first_bd = sorted_bases[0]\n",
    "    for bd in sorted_bases:\n",
    "        day_diff = (bd - first_bd).days\n",
    "        if day_diff % 5 == 0:\n",
    "            chosen.append(bd)\n",
    "    if sorted_bases[-1] not in chosen:\n",
    "        chosen.append(sorted_bases[-1])\n",
    "    return sorted(chosen)\n",
    "\n",
    "############################################\n",
    "# 10. Zoom-in Joint Diagram (10th) + Model-by-Model (5th or 10th)\n",
    "############################################\n",
    "def plot_joint_10day_forecasts_zoom_in(final_rolling_fcst, df_actual,\n",
    "                                       start_date_plot, end_date_plot):\n",
    "    \"\"\"\n",
    "    Single figure: Actual Price + multiple model forecasts from every 10th BaseDate,\n",
    "    restricted to y-axis [28..33].\n",
    "    \"\"\"\n",
    "    color_map = {\n",
    "        \"LSTM\": \"red\",\n",
    "        \"GRU\": \"blue\",\n",
    "        \"RNN\": \"green\",\n",
    "        \"CNN\": \"orange\",\n",
    "        \"EnhancedLSTM\": \"magenta\",\n",
    "        \"Transformer\": \"cyan\",\n",
    "        \"N-BEATS\": \"brown\",\n",
    "        \"N-HITS\": \"pink\",\n",
    "        \"SVM\": \"olive\",\n",
    "        \"GPR\": \"teal\",\n",
    "        \"Boost\": \"purple\"\n",
    "    }\n",
    "    df_plot = df_actual[\n",
    "        (df_actual[\"Date\"]>=start_date_plot) & (df_actual[\"Date\"]<= end_date_plot)\n",
    "    ].copy()\n",
    "\n",
    "    base_dates = pick_every_10th_base_dates(final_rolling_fcst[\"BaseDate\"].unique())\n",
    "\n",
    "    plt.figure(figsize=(12,6))\n",
    "    # Actual\n",
    "    plt.plot(df_plot[\"Date\"], df_plot[\"Price\"], color=\"black\", lw=2, label=\"Actual Price\")\n",
    "\n",
    "    models = final_rolling_fcst[\"Model\"].unique()\n",
    "    for m in models:\n",
    "        df_m = final_rolling_fcst[final_rolling_fcst[\"Model\"]==m].copy()\n",
    "        c = color_map.get(m, \"gray\")\n",
    "        for bd in base_dates:\n",
    "            df_bd = df_m[df_m[\"BaseDate\"]==bd].copy()\n",
    "            df_bd = df_bd[(df_bd[\"ForecastDate\"]>=start_date_plot) & (df_bd[\"ForecastDate\"]<=end_date_plot)]\n",
    "            if len(df_bd)==0:\n",
    "                continue\n",
    "            plt.plot(df_bd[\"ForecastDate\"], df_bd[\"Pred_Price_unscaled\"], color=c, alpha=0.4)\n",
    "\n",
    "    legend_elems = [Line2D([0],[0], color=\"black\", lw=2, label=\"Actual Price\")]\n",
    "    for m in models:\n",
    "        legend_elems.append(Line2D([0],[0], color=color_map.get(m,\"gray\"), lw=2, label=m))\n",
    "    plt.legend(handles=legend_elems, loc=\"best\")\n",
    "\n",
    "    #plt.ylim(28, 33)  # y-axis restriction\n",
    "    plt.title(f\"Zoom-in Joint Diagram (Every 10th BaseDate)\\n{start_date_plot.date()} ~ {end_date_plot.date()} of Brent Oil Futures \")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def plot_each_model_10days(final_rolling_fcst, df_actual,\n",
    "                           start_date_plot, end_date_plot):\n",
    "    \"\"\"\n",
    "    Model-by-model Rolling Forecast, using every 10th BaseDate, no y-limit.\n",
    "    \"\"\"\n",
    "    models = sorted(final_rolling_fcst[\"Model\"].unique())\n",
    "    df_plot = df_actual[\n",
    "        (df_actual[\"Date\"]>=start_date_plot) & (df_actual[\"Date\"]<=end_date_plot)\n",
    "    ].copy()\n",
    "\n",
    "    base_dates = pick_every_10th_base_dates(final_rolling_fcst[\"BaseDate\"].unique())\n",
    "\n",
    "    for m in models:\n",
    "        df_m = final_rolling_fcst[final_rolling_fcst[\"Model\"]==m].copy()\n",
    "        plt.figure(figsize=(10,5))\n",
    "        # Actual\n",
    "        plt.plot(df_plot[\"Date\"], df_plot[\"Price\"], color=\"black\", lw=2, label=\"Actual Price\")\n",
    "\n",
    "        for bd in base_dates:\n",
    "            df_bd = df_m[df_m[\"BaseDate\"]==bd].copy()\n",
    "            df_bd= df_bd[(df_bd[\"ForecastDate\"]>=start_date_plot) & (df_bd[\"ForecastDate\"]<=end_date_plot)]\n",
    "            if len(df_bd)==0:\n",
    "                continue\n",
    "            plt.plot(df_bd[\"ForecastDate\"], df_bd[\"Pred_Price_unscaled\"], alpha=0.6)\n",
    "\n",
    "        plt.title(f\"{m}: Rolling Forecast (Every 10th BaseDate) of Brent Oil Futures \")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.grid(True)\n",
    "        plt.legend(prop={\"size\":7})\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_each_model_5days(final_rolling_fcst, df_actual,\n",
    "                          start_date_plot, end_date_plot):\n",
    "    \"\"\"\n",
    "    Model-by-model Rolling Forecast, using every 5th BaseDate, no y-limit.\n",
    "    \"\"\"\n",
    "    models = sorted(final_rolling_fcst[\"Model\"].unique())\n",
    "    df_plot = df_actual[\n",
    "        (df_actual[\"Date\"]>=start_date_plot) & (df_actual[\"Date\"]<=end_date_plot)\n",
    "    ].copy()\n",
    "\n",
    "    base_dates = pick_every_5th_base_dates(final_rolling_fcst[\"BaseDate\"].unique())\n",
    "\n",
    "    for m in models:\n",
    "        df_m = final_rolling_fcst[final_rolling_fcst[\"Model\"]==m].copy()\n",
    "        plt.figure(figsize=(10,5))\n",
    "        # Actual\n",
    "        plt.plot(df_plot[\"Date\"], df_plot[\"Price\"], color=\"black\", lw=2, label=\"Actual Price\")\n",
    "\n",
    "        for bd in base_dates:\n",
    "            df_bd = df_m[df_m[\"BaseDate\"]==bd].copy()\n",
    "            df_bd= df_bd[(df_bd[\"ForecastDate\"]>=start_date_plot) & (df_bd[\"ForecastDate\"]<=end_date_plot)]\n",
    "            if len(df_bd)==0:\n",
    "                continue\n",
    "            plt.plot(df_bd[\"ForecastDate\"], df_bd[\"Pred_Price_unscaled\"], alpha=0.6)\n",
    "\n",
    "        plt.title(f\"{m}: Rolling Forecast (Every 5th BaseDate) of Brent Oil Futures \")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        plt.grid(True)\n",
    "        plt.legend(prop={\"size\":7})\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "############################################\n",
    "# 11. MAIN\n",
    "############################################\n",
    "if __name__==\"__main__\":\n",
    "    # 1) Load & scale data\n",
    "    df_scaled, df_complete_all, scaler = load_and_scale_data(\n",
    "        \"Brent Oil Futures Historical Data.csv\",\n",
    "        \"Brent Oil Futures Historical Data_Complete.csv\"\n",
    "    )\n",
    "\n",
    "    # 2) Perform rolling approach: LOAD models only,\n",
    "    #    daily rolling plots only on final day (2025-02-28)\n",
    "    final_rolling_fc = rolling_train_validate_predict_moe(\n",
    "        df_full=df_complete_all,\n",
    "        scaler_obj=scaler,\n",
    "        model_types=[\"LSTM\",\"GRU\",\"RNN\",\"CNN\",\"Transformer\",\"N-BEATS\",\"N-HITS\",\"SVM\",\"Boost\"],\n",
    "        start_train_cutoff=pd.to_datetime(\"2024-08-01\"),\n",
    "        start_val_cutoff=pd.to_datetime(\"2024-12-30\"),\n",
    "        start_pred=pd.to_datetime(\"2025-01-01\"),\n",
    "        end_pred=pd.to_datetime(\"2025-02-01\"),\n",
    "        horizon_days=30,\n",
    "        do_daily_plots=True   # but effectively only for final day\n",
    "    )\n",
    "\n",
    "    # 3) Plot final rolling forecast\n",
    "    print(\"\\n===== ROLLING FC HEAD =====\")\n",
    "    print(final_rolling_fc.head(50))\n",
    "    plot_final_rolling_fc(\n",
    "        final_rolling_fc,\n",
    "        df_complete_all, \n",
    "        from_d=pd.to_datetime(\"2025-01-01\"),\n",
    "        to_d=pd.to_datetime(\"2025-02-28\")\n",
    "    )\n",
    "\n",
    "    # 4) Additional diagrams:\n",
    "\n",
    "    # A) 2025-01-01 ~ 2025-03-01\n",
    "    #    - Zoom-in Joint Diagram => every 10th base date, y-limited [28..33]\n",
    "    #    - Model-by-model => every 10th base date\n",
    "    print(\"\\n=== PLOTS for 2025-01-01 to 2025-02-28 ===\")\n",
    "    plot_joint_10day_forecasts_zoom_in(\n",
    "        final_rolling_fc,\n",
    "        df_complete_all,\n",
    "        start_date_plot=pd.to_datetime(\"2025-01-01\"),\n",
    "        end_date_plot=pd.to_datetime(\"2025-02-28\")\n",
    "    )\n",
    "    plot_each_model_10days(\n",
    "        final_rolling_fc,\n",
    "        df_complete_all,\n",
    "        start_date_plot=pd.to_datetime(\"2025-01-01\"),\n",
    "        end_date_plot=pd.to_datetime(\"2025-02-28\")\n",
    "    )\n",
    "\n",
    "    # B) 2025-01-01 ~ 2025-02-01\n",
    "    #    - Zoom-in Joint Diagram => every 10th base date, y-limited [28..33]\n",
    "    #    - Model-by-model => every 5th base date\n",
    "    print(\"\\n=== PLOTS for 2025-01-01 to 2025-01-01 ===\")\n",
    "    plot_joint_10day_forecasts_zoom_in(\n",
    "        final_rolling_fc,\n",
    "        df_complete_all,\n",
    "        start_date_plot=pd.to_datetime(\"2025-01-01\"),\n",
    "        end_date_plot=pd.to_datetime(\"2025-01-01\")\n",
    "    )\n",
    "    plot_each_model_5days(\n",
    "        final_rolling_fc,\n",
    "        df_complete_all,\n",
    "        start_date_plot=pd.to_datetime(\"2025-01-01\"),\n",
    "        end_date_plot=pd.to_datetime(\"2025-01-01\")\n",
    "    )\n",
    "\n",
    "    # C) 2025-02-01 ~ 2025-03-01\n",
    "    #    - Zoom-in Joint Diagram => every 10th base date, y-limited [28..33]\n",
    "    #    - Model-by-model => every 5th base date\n",
    "    print(\"\\n=== PLOTS for 2025-02-01 to 2025-02-28 ===\")\n",
    "    plot_joint_10day_forecasts_zoom_in(\n",
    "        final_rolling_fc,\n",
    "        df_complete_all,\n",
    "        start_date_plot=pd.to_datetime(\"2025-02-01\"),\n",
    "        end_date_plot=pd.to_datetime(\"2025-02-28\")\n",
    "    )\n",
    "    plot_each_model_5days(\n",
    "        final_rolling_fc,\n",
    "        df_complete_all,\n",
    "        start_date_plot=pd.to_datetime(\"2025-02-01\"),\n",
    "        end_date_plot=pd.to_datetime(\"2025-02-28\")\n",
    "    )\n",
    "\n",
    "    print(\"\\nAll done.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
