{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===== TRAINING CSV INFO =====\n",
      "CSV date range:\n",
      "  Min date: 2021-01-04 00:00:00\n",
      "  Max date: 2025-01-31 00:00:00\n",
      "Number of rows in df: 1067\n",
      "Rows that have all features = NaN: 21\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-02 ===\n",
      "Training cutoff: 2024-08-01, Validation cutoff: 2024-12-31\n",
      "\n",
      "--- Training LSTM for base date 2025-01-02 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-02_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-02 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-02_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-02 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-02_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-02 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-02_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-02 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-02_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-02 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-02_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-02 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-02_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-02 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-02_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-02 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-02_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-03 ===\n",
      "Training cutoff: 2024-08-02, Validation cutoff: 2025-01-01\n",
      "\n",
      "--- Training LSTM for base date 2025-01-03 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-03_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-03 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-03_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-03 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-03_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-03 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-03_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-03 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-03_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-03 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-03_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-03 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-03_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-03 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-03_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-03 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-03_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-04 ===\n",
      "Training cutoff: 2024-08-03, Validation cutoff: 2025-01-02\n",
      "\n",
      "--- Training LSTM for base date 2025-01-04 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-04_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-04 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-04_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-04 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-04_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-04 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-04_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-04 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-04_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-04 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-04_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-04 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-04_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-04 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-04_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-04 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-04_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-05 ===\n",
      "Training cutoff: 2024-08-04, Validation cutoff: 2025-01-03\n",
      "\n",
      "--- Training LSTM for base date 2025-01-05 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-05_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-05 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-05_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-05 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-05_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-05 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-05_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-05 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-05_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-05 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-05_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-05 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-05_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-05 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-05_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-05 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-05_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-06 ===\n",
      "Training cutoff: 2024-08-05, Validation cutoff: 2025-01-04\n",
      "\n",
      "--- Training LSTM for base date 2025-01-06 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-06_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-06 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-06_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-06 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-06_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-06 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-06_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-06 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-06_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-06 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-06_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-06 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-06_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-06 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-06_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-06 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-06_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-07 ===\n",
      "Training cutoff: 2024-08-06, Validation cutoff: 2025-01-05\n",
      "\n",
      "--- Training LSTM for base date 2025-01-07 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-07_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-07 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-07_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-07 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-07_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-07 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-07_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-07 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-07_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-07 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-07_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-07 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-07_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-07 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-07_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-07 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-07_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-08 ===\n",
      "Training cutoff: 2024-08-07, Validation cutoff: 2025-01-06\n",
      "\n",
      "--- Training LSTM for base date 2025-01-08 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-08_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-08 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-08_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-08 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-08_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-08 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-08_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-08 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-08_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-08 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-08_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-08 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-08_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-08 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-08_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-08 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-08_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-09 ===\n",
      "Training cutoff: 2024-08-08, Validation cutoff: 2025-01-07\n",
      "\n",
      "--- Training LSTM for base date 2025-01-09 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-09_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-09 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-09_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-09 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-09_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-09 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-09_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-09 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-09_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-09 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-09_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-09 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-09_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-09 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-09_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-09 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-09_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-10 ===\n",
      "Training cutoff: 2024-08-09, Validation cutoff: 2025-01-08\n",
      "\n",
      "--- Training LSTM for base date 2025-01-10 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-10_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-10 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-10_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-10 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-10_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-10 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-10_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-10 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-10_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-10 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-10_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-10 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-10_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-10 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-10_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-10 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-10_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-11 ===\n",
      "Training cutoff: 2024-08-10, Validation cutoff: 2025-01-09\n",
      "\n",
      "--- Training LSTM for base date 2025-01-11 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-11_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-11 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-11_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-11 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-11_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-11 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-11_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-11 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-11_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-11 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-11_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-11 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-11_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-11 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-11_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-11 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-11_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-12 ===\n",
      "Training cutoff: 2024-08-11, Validation cutoff: 2025-01-10\n",
      "\n",
      "--- Training LSTM for base date 2025-01-12 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-12_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-12 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-12_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-12 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-12_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-12 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-12_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-12 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-12_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-12 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-12_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-12 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-12_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-12 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-12_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-12 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-12_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-13 ===\n",
      "Training cutoff: 2024-08-12, Validation cutoff: 2025-01-11\n",
      "\n",
      "--- Training LSTM for base date 2025-01-13 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-13_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-13 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-13_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-13 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-13_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-13 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-13_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-13 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-13_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-13 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-13_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-13 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-13_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-13 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-13_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-13 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-13_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-14 ===\n",
      "Training cutoff: 2024-08-13, Validation cutoff: 2025-01-12\n",
      "\n",
      "--- Training LSTM for base date 2025-01-14 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-14_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-14 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-14_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-14 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-14_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-14 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-14_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-14 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-14_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-14 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-14_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-14 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-14_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-14 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-14_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-14 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-14_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-15 ===\n",
      "Training cutoff: 2024-08-14, Validation cutoff: 2025-01-13\n",
      "\n",
      "--- Training LSTM for base date 2025-01-15 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-15_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-15 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-15_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-15 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-15_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-15 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-15_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-15 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-15_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-15 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-15_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-15 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-15_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-15 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-15_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-15 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-15_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-16 ===\n",
      "Training cutoff: 2024-08-15, Validation cutoff: 2025-01-14\n",
      "\n",
      "--- Training LSTM for base date 2025-01-16 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-16_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-16 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-16_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-16 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-16_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-16 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-16_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-16 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-16_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-16 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-16_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-16 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-16_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-16 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-16_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-16 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-16_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-17 ===\n",
      "Training cutoff: 2024-08-16, Validation cutoff: 2025-01-15\n",
      "\n",
      "--- Training LSTM for base date 2025-01-17 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-17_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-17 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-17_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-17 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-17_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-17 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-17_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-17 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-17_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-17 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-17_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-17 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-17_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-17 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-17_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-17 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-17_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-18 ===\n",
      "Training cutoff: 2024-08-17, Validation cutoff: 2025-01-16\n",
      "\n",
      "--- Training LSTM for base date 2025-01-18 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-18_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-18 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-18_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-18 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-18_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-18 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-18_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-18 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-18_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-18 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-18_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-18 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-18_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-18 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-18_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-18 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-18_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-19 ===\n",
      "Training cutoff: 2024-08-18, Validation cutoff: 2025-01-17\n",
      "\n",
      "--- Training LSTM for base date 2025-01-19 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-19_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-19 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-19_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-19 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-19_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-19 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-19_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-19 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-19_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-19 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-19_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-19 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-19_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-19 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-19_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-19 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-19_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-20 ===\n",
      "Training cutoff: 2024-08-19, Validation cutoff: 2025-01-18\n",
      "\n",
      "--- Training LSTM for base date 2025-01-20 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-20_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-20 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-20_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-20 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-20_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-20 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-20_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-20 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-20_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-20 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-20_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-20 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-20_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-20 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-20_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-20 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-20_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-21 ===\n",
      "Training cutoff: 2024-08-20, Validation cutoff: 2025-01-19\n",
      "\n",
      "--- Training LSTM for base date 2025-01-21 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-21_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-21 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-21_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-21 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-21_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-21 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-21_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-21 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-21_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-21 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-21_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-21 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-21_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-21 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-21_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-21 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-21_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-22 ===\n",
      "Training cutoff: 2024-08-21, Validation cutoff: 2025-01-20\n",
      "\n",
      "--- Training LSTM for base date 2025-01-22 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-22_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-22 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-22_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-22 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-22_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-22 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-22_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-22 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-22_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-22 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-22_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-22 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-22_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-22 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-22_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-22 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-22_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-23 ===\n",
      "Training cutoff: 2024-08-22, Validation cutoff: 2025-01-21\n",
      "\n",
      "--- Training LSTM for base date 2025-01-23 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-23_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-23 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-23_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-23 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-23_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-23 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-23_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-23 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-23_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-23 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-23_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-23 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-23_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-23 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-23_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-23 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-23_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-24 ===\n",
      "Training cutoff: 2024-08-23, Validation cutoff: 2025-01-22\n",
      "\n",
      "--- Training LSTM for base date 2025-01-24 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-24_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-24 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-24_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-24 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-24_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-24 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-24_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-24 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-24_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-24 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-24_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-24 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-24_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-24 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-24_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-24 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-24_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-25 ===\n",
      "Training cutoff: 2024-08-24, Validation cutoff: 2025-01-23\n",
      "\n",
      "--- Training LSTM for base date 2025-01-25 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-25_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-25 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-25_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-25 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-25_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-25 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-25_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-25 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-25_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-25 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-25_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-25 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-25_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-25 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-25_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-25 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-25_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-26 ===\n",
      "Training cutoff: 2024-08-25, Validation cutoff: 2025-01-24\n",
      "\n",
      "--- Training LSTM for base date 2025-01-26 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-26_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-26 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-26_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-26 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-26_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-26 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-26_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-26 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-26_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-26 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-26_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-26 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-26_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-26 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-26_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-26 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-26_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-27 ===\n",
      "Training cutoff: 2024-08-26, Validation cutoff: 2025-01-25\n",
      "\n",
      "--- Training LSTM for base date 2025-01-27 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-27_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-27 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-27_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-27 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-27_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-27 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-27_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-27 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-27_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-27 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-27_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-27 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-27_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-27 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-27_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-27 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-27_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-28 ===\n",
      "Training cutoff: 2024-08-27, Validation cutoff: 2025-01-26\n",
      "\n",
      "--- Training LSTM for base date 2025-01-28 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-28_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-28 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-28_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-28 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-28_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-28 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-28_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-28 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-28_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-28 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-28_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-28 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-28_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-28 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-28_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-28 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-28_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-29 ===\n",
      "Training cutoff: 2024-08-28, Validation cutoff: 2025-01-27\n",
      "\n",
      "--- Training LSTM for base date 2025-01-29 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-29_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-29 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-29_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-29 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-29_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-29 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-29_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-29 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-29_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-29 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-29_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-29 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-29_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-29 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-29_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-29 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-29_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-30 ===\n",
      "Training cutoff: 2024-08-29, Validation cutoff: 2025-01-28\n",
      "\n",
      "--- Training LSTM for base date 2025-01-30 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-30_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-30 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-30_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-30 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-30_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-30 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-30_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-30 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-30_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-30 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-30_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-30 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-30_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-30 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-30_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-30 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-30_Mixture of Experts_V1.pkl\n",
      "\n",
      "=== Rolling Window for Base Date 2025-01-31 ===\n",
      "Training cutoff: 2024-08-30, Validation cutoff: 2025-01-29\n",
      "\n",
      "--- Training LSTM for base date 2025-01-31 ---\n",
      "[LSTM] Loaded existing model from ./best_LSTM_2025-01-31_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training GRU for base date 2025-01-31 ---\n",
      "[GRU] Loaded existing model from ./best_GRU_2025-01-31_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training RNN for base date 2025-01-31 ---\n",
      "[RNN] Loaded existing model from ./best_RNN_2025-01-31_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training CNN for base date 2025-01-31 ---\n",
      "[CNN] Loaded existing model from ./best_CNN_2025-01-31_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training Transformer for base date 2025-01-31 ---\n",
      "[Transformer] Loaded existing model from ./best_Transformer_2025-01-31_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-BEATS for base date 2025-01-31 ---\n",
      "[N-BEATS] Loaded existing model from ./best_N-BEATS_2025-01-31_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training N-HITS for base date 2025-01-31 ---\n",
      "[N-HITS] Loaded existing model from ./best_N-HITS_2025-01-31_Mixture of Experts_V1.pt\n",
      "\n",
      "--- Training SVM for base date 2025-01-31 ---\n",
      "[SVM] Loaded existing model from ./best_SVM_2025-01-31_Mixture of Experts_V1.pkl\n",
      "\n",
      "--- Training Boost for base date 2025-01-31 ---\n",
      "[Boost] Loaded existing model from ./best_Boost_2025-01-31_Mixture of Experts_V1.pkl\n",
      "\n",
      "===== ROLLING FORECASTS (Rolling Training + MOE) =====\n",
      "   ForecastDate  Pred_Price_unscaled  Pred_Open_unscaled  Pred_High_unscaled  \\\n",
      "0    2025-01-02            19.007692           17.892870           18.990448   \n",
      "1    2025-01-03            19.790785           18.938288           20.073067   \n",
      "2    2025-01-04            19.984734           19.619598           20.373779   \n",
      "3    2025-01-05            20.580751           20.043829           21.024885   \n",
      "4    2025-01-06            20.713881           20.748922           21.557068   \n",
      "5    2025-01-07            20.764723           20.764578           21.580996   \n",
      "6    2025-01-08            20.747820           20.786871           21.491640   \n",
      "7    2025-01-09            20.669455           20.875090           21.488947   \n",
      "8    2025-01-10            20.715918           20.886551           21.551655   \n",
      "9    2025-01-11            20.746031           20.904724           21.534475   \n",
      "10   2025-01-12            20.746031           20.798836           21.503942   \n",
      "11   2025-01-13            20.734728           20.852135           21.516634   \n",
      "12   2025-01-14            20.773487           20.884455           21.499451   \n",
      "13   2025-01-15            20.769722           20.852205           21.540197   \n",
      "14   2025-01-16            20.769722           20.866394           21.498945   \n",
      "15   2025-01-17            20.691311           20.871643           21.490023   \n",
      "16   2025-01-18            20.883003           20.888432           21.525785   \n",
      "17   2025-01-19            21.252728           20.942036           21.589273   \n",
      "18   2025-01-20            21.359621           21.345854           21.884008   \n",
      "19   2025-01-21            21.359621           21.524565           21.916866   \n",
      "20   2025-01-22            21.299673           21.543520           21.927349   \n",
      "21   2025-01-23            21.098173           21.436470           21.647388   \n",
      "22   2025-01-24            21.037203           21.258528           21.553741   \n",
      "23   2025-01-25            20.960190           21.319462           21.363907   \n",
      "24   2025-01-26            20.884449           21.163939           21.374868   \n",
      "25   2025-01-27            20.623291           21.064396           21.021448   \n",
      "26   2025-01-28            20.737226           21.022558           20.952694   \n",
      "27   2025-01-29            20.533854           21.027693           21.091154   \n",
      "28   2025-01-30            20.540592           21.056934           21.175707   \n",
      "29   2025-01-31            20.693525           21.117245           21.175707   \n",
      "30   2025-01-03            19.139574           17.901335           19.161930   \n",
      "31   2025-01-04            19.782457           19.147970           20.483109   \n",
      "32   2025-01-05            20.154867           19.794937           20.761251   \n",
      "33   2025-01-06            20.729479           20.103958           21.159195   \n",
      "34   2025-01-07            21.282967           20.749411           21.724411   \n",
      "35   2025-01-08            21.614479           21.298145           22.109217   \n",
      "36   2025-01-09            21.899929           21.712507           22.435049   \n",
      "37   2025-01-10            22.193790           22.099804           22.563387   \n",
      "38   2025-01-11            22.504963           22.480244           22.963617   \n",
      "39   2025-01-12            22.837036           22.895473           23.135777   \n",
      "40   2025-01-13            23.111122           23.205605           23.479105   \n",
      "41   2025-01-14            23.397171           23.360458           23.683071   \n",
      "42   2025-01-15            23.641241           23.784029           24.089394   \n",
      "43   2025-01-16            24.120222           23.911427           24.386147   \n",
      "44   2025-01-17            24.564735           24.176752           24.869656   \n",
      "45   2025-01-18            25.043886           24.554340           25.357500   \n",
      "46   2025-01-19            25.418087           25.147316           26.057823   \n",
      "47   2025-01-20            25.764652           25.413475           26.261494   \n",
      "48   2025-01-21            26.041891           25.960056           26.933821   \n",
      "49   2025-01-22            26.011145           26.160042           27.183016   \n",
      "\n",
      "    Pred_Low_unscaled   BaseDate  Model  \n",
      "0           18.056042 2025-01-02  Boost  \n",
      "1           18.820330 2025-01-02  Boost  \n",
      "2           19.301537 2025-01-02  Boost  \n",
      "3           19.737904 2025-01-02  Boost  \n",
      "4           20.280411 2025-01-02  Boost  \n",
      "5           20.273300 2025-01-02  Boost  \n",
      "6           20.259954 2025-01-02  Boost  \n",
      "7           20.356026 2025-01-02  Boost  \n",
      "8           20.486242 2025-01-02  Boost  \n",
      "9           20.449453 2025-01-02  Boost  \n",
      "10          20.315241 2025-01-02  Boost  \n",
      "11          20.356838 2025-01-02  Boost  \n",
      "12          20.423264 2025-01-02  Boost  \n",
      "13          20.190941 2025-01-02  Boost  \n",
      "14          20.185421 2025-01-02  Boost  \n",
      "15          20.185421 2025-01-02  Boost  \n",
      "16          20.289209 2025-01-02  Boost  \n",
      "17          20.526535 2025-01-02  Boost  \n",
      "18          20.790573 2025-01-02  Boost  \n",
      "19          20.960484 2025-01-02  Boost  \n",
      "20          20.955128 2025-01-02  Boost  \n",
      "21          21.024927 2025-01-02  Boost  \n",
      "22          20.939316 2025-01-02  Boost  \n",
      "23          20.762196 2025-01-02  Boost  \n",
      "24          20.726982 2025-01-02  Boost  \n",
      "25          20.735353 2025-01-02  Boost  \n",
      "26          20.541594 2025-01-02  Boost  \n",
      "27          20.489124 2025-01-02  Boost  \n",
      "28          20.478796 2025-01-02  Boost  \n",
      "29          20.502796 2025-01-02  Boost  \n",
      "30          18.240734 2025-01-03  Boost  \n",
      "31          19.005795 2025-01-03  Boost  \n",
      "32          19.464861 2025-01-03  Boost  \n",
      "33          19.880236 2025-01-03  Boost  \n",
      "34          20.432486 2025-01-03  Boost  \n",
      "35          20.961353 2025-01-03  Boost  \n",
      "36          21.446283 2025-01-03  Boost  \n",
      "37          21.806026 2025-01-03  Boost  \n",
      "38          22.261614 2025-01-03  Boost  \n",
      "39          22.585051 2025-01-03  Boost  \n",
      "40          22.890400 2025-01-03  Boost  \n",
      "41          23.004017 2025-01-03  Boost  \n",
      "42          23.436167 2025-01-03  Boost  \n",
      "43          23.546200 2025-01-03  Boost  \n",
      "44          23.827316 2025-01-03  Boost  \n",
      "45          24.262421 2025-01-03  Boost  \n",
      "46          24.861036 2025-01-03  Boost  \n",
      "47          24.931429 2025-01-03  Boost  \n",
      "48          25.292311 2025-01-03  Boost  \n",
      "49          25.671646 2025-01-03  Boost  \n",
      "Total rows in rolling forecast: 8100\n",
      "\n",
      "=== 2025-01-02 ===\n",
      "  Model=Transformer, Error=1.163, Conf=1.000\n",
      "  Model=SVM, Error=4.108, Conf=0.936\n",
      "  Model=CNN, Error=5.576, Conf=0.905\n",
      "\n",
      "=== 2025-01-03 ===\n",
      "  Model=Transformer, Error=0.946, Conf=1.000\n",
      "  Model=Transformer, Error=1.161, Conf=0.999\n",
      "  Model=LSTM, Error=1.860, Conf=0.996\n",
      "\n",
      "=== 2025-01-06 ===\n",
      "  Model=LSTM, Error=1.106, Conf=1.000\n",
      "  Model=N-HITS, Error=1.363, Conf=0.998\n",
      "  Model=Transformer, Error=1.427, Conf=0.998\n",
      "\n",
      "=== 2025-01-07 ===\n",
      "  Model=LSTM, Error=0.158, Conf=1.000\n",
      "  Model=Transformer, Error=1.383, Conf=0.992\n",
      "  Model=Transformer, Error=1.432, Conf=0.991\n",
      "\n",
      "=== 2025-01-08 ===\n",
      "  Model=Transformer, Error=0.256, Conf=1.000\n",
      "  Model=LSTM, Error=0.587, Conf=0.998\n",
      "  Model=LSTM, Error=1.096, Conf=0.994\n",
      "\n",
      "=== 2025-01-09 ===\n",
      "  Model=RNN, Error=0.091, Conf=1.000\n",
      "  Model=LSTM, Error=0.118, Conf=1.000\n",
      "  Model=Transformer, Error=1.143, Conf=0.993\n",
      "\n",
      "=== 2025-01-10 ===\n",
      "  Model=LSTM, Error=0.002, Conf=1.000\n",
      "  Model=CNN, Error=1.163, Conf=0.993\n",
      "  Model=RNN, Error=1.165, Conf=0.993\n",
      "\n",
      "=== 2025-01-13 ===\n",
      "  Model=LSTM, Error=0.474, Conf=1.000\n",
      "  Model=RNN, Error=0.620, Conf=1.000\n",
      "  Model=Transformer, Error=0.633, Conf=0.999\n",
      "\n",
      "=== 2025-01-14 ===\n",
      "  Model=LSTM, Error=0.093, Conf=1.000\n",
      "  Model=LSTM, Error=0.106, Conf=1.000\n",
      "  Model=LSTM, Error=0.366, Conf=0.999\n",
      "\n",
      "=== 2025-01-15 ===\n",
      "  Model=LSTM, Error=0.169, Conf=1.000\n",
      "  Model=RNN, Error=0.623, Conf=0.999\n",
      "  Model=CNN, Error=0.657, Conf=0.999\n",
      "\n",
      "=== 2025-01-16 ===\n",
      "  Model=LSTM, Error=0.315, Conf=1.000\n",
      "  Model=CNN, Error=0.677, Conf=0.999\n",
      "  Model=LSTM, Error=0.849, Conf=0.999\n",
      "\n",
      "=== 2025-01-17 ===\n",
      "  Model=LSTM, Error=0.014, Conf=1.000\n",
      "  Model=LSTM, Error=0.161, Conf=1.000\n",
      "  Model=LSTM, Error=0.282, Conf=1.000\n",
      "\n",
      "=== 2025-01-21 ===\n",
      "  Model=LSTM, Error=0.075, Conf=1.000\n",
      "  Model=LSTM, Error=0.104, Conf=1.000\n",
      "  Model=Transformer, Error=0.158, Conf=1.000\n",
      "\n",
      "=== 2025-01-22 ===\n",
      "  Model=LSTM, Error=0.010, Conf=1.000\n",
      "  Model=LSTM, Error=0.021, Conf=1.000\n",
      "  Model=LSTM, Error=0.238, Conf=1.000\n",
      "\n",
      "=== 2025-01-23 ===\n",
      "  Model=LSTM, Error=0.077, Conf=1.000\n",
      "  Model=RNN, Error=0.151, Conf=1.000\n",
      "  Model=LSTM, Error=0.280, Conf=1.000\n",
      "\n",
      "=== 2025-01-24 ===\n",
      "  Model=LSTM, Error=0.034, Conf=1.000\n",
      "  Model=RNN, Error=0.087, Conf=1.000\n",
      "  Model=LSTM, Error=0.347, Conf=1.000\n",
      "\n",
      "=== 2025-01-27 ===\n",
      "  Model=Transformer, Error=0.055, Conf=1.000\n",
      "  Model=LSTM, Error=0.060, Conf=1.000\n",
      "  Model=Transformer, Error=0.083, Conf=1.000\n",
      "\n",
      "=== 2025-01-28 ===\n",
      "  Model=CNN, Error=0.035, Conf=1.000\n",
      "  Model=RNN, Error=0.154, Conf=1.000\n",
      "  Model=Transformer, Error=0.198, Conf=1.000\n",
      "\n",
      "=== 2025-01-29 ===\n",
      "  Model=LSTM, Error=0.083, Conf=1.000\n",
      "  Model=LSTM, Error=0.086, Conf=1.000\n",
      "  Model=CNN, Error=0.200, Conf=1.000\n",
      "\n",
      "=== 2025-01-30 ===\n",
      "  Model=LSTM, Error=0.021, Conf=1.000\n",
      "  Model=LSTM, Error=0.070, Conf=1.000\n",
      "  Model=LSTM, Error=0.113, Conf=1.000\n",
      "\n",
      "=== 2025-01-31 ===\n",
      "  Model=RNN, Error=0.014, Conf=1.000\n",
      "  Model=LSTM, Error=0.115, Conf=1.000\n",
      "  Model=LSTM, Error=0.204, Conf=1.000\n",
      "\n",
      "===== Best Model of the Day (highest confidence) =====\n",
      "2025-01-02: Transformer (Conf=1.000, Error=1.163)\n",
      "2025-01-03: Transformer (Conf=1.000, Error=0.946)\n",
      "2025-01-06: LSTM (Conf=1.000, Error=1.106)\n",
      "2025-01-07: LSTM (Conf=1.000, Error=0.158)\n",
      "2025-01-08: Transformer (Conf=1.000, Error=0.256)\n",
      "2025-01-09: RNN (Conf=1.000, Error=0.091)\n",
      "2025-01-10: LSTM (Conf=1.000, Error=0.002)\n",
      "2025-01-13: LSTM (Conf=1.000, Error=0.474)\n",
      "2025-01-14: LSTM (Conf=1.000, Error=0.093)\n",
      "2025-01-15: LSTM (Conf=1.000, Error=0.169)\n",
      "2025-01-16: LSTM (Conf=1.000, Error=0.315)\n",
      "2025-01-17: LSTM (Conf=1.000, Error=0.014)\n",
      "2025-01-21: LSTM (Conf=1.000, Error=0.075)\n",
      "2025-01-22: LSTM (Conf=1.000, Error=0.010)\n",
      "2025-01-23: LSTM (Conf=1.000, Error=0.077)\n",
      "2025-01-24: LSTM (Conf=1.000, Error=0.034)\n",
      "2025-01-27: Transformer (Conf=1.000, Error=0.055)\n",
      "2025-01-28: CNN (Conf=1.000, Error=0.035)\n",
      "2025-01-29: LSTM (Conf=1.000, Error=0.083)\n",
      "2025-01-30: LSTM (Conf=1.000, Error=0.021)\n",
      "2025-01-31: RNN (Conf=1.000, Error=0.014)\n",
      "\n",
      "===== MOE DataFrame (head) =====\n",
      "   ForecastDate   MOE_Pred  ActualPrice  MOE_AbsError\n",
      "0    2025-01-02  26.361032       29.900      3.538968\n",
      "1    2025-01-03  28.743378       30.065      1.321622\n",
      "2    2025-01-06  30.022763       30.583      0.560237\n",
      "3    2025-01-07  29.697367       30.686      0.988633\n",
      "4    2025-01-08  30.772873       30.690      0.082873\n",
      "5    2025-01-09  30.705448       31.015      0.309552\n",
      "6    2025-01-10  30.538961       31.314      0.775039\n",
      "7    2025-01-13  30.462809       30.309      0.153809\n",
      "8    2025-01-14  30.233438       30.351      0.117562\n",
      "9    2025-01-15  31.463624       31.531      0.067376\n",
      "10   2025-01-16  31.772785       31.725      0.047785\n",
      "11   2025-01-17  31.105325       31.141      0.035675\n",
      "12   2025-01-21  31.538977       31.496      0.042977\n",
      "13   2025-01-22  31.495554       31.420      0.075554\n",
      "14   2025-01-23  30.881177       30.712      0.169177\n",
      "15   2025-01-24  31.188618       31.055      0.133618\n",
      "16   2025-01-27  30.312195       30.283      0.029195\n",
      "17   2025-01-28  30.860753       30.755      0.105753\n",
      "18   2025-01-29  31.331699       31.264      0.067699\n",
      "19   2025-01-30  32.471528       32.493      0.021472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_462847/3394875629.py:442: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n",
      "  df_out = df_merged.groupby(\"ForecastDate\", group_keys=False).apply(group_conf)\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "All done with rolling training, validation and prediction.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import timedelta\n",
    "\n",
    "# 1) SUPPRESS ALL WARNINGS\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# ============================================\n",
    "# Global seeds & settings\n",
    "# ============================================\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "# Hyperparameters\n",
    "WINDOW_SIZE = 35\n",
    "NUM_EPOCHS  = 100\n",
    "features = [\"Price\", \"Open\", \"High\", \"Low\"]\n",
    "\n",
    "# File paths\n",
    "csv_file_train    = \"Silver Futures Historical Data.csv\"\n",
    "csv_file_complete = \"Silver Futures Historical Data_Complete.csv\"\n",
    "best_models_dir   = \".\"\n",
    "\n",
    "# ============================================\n",
    "# 2. Load & Clean CSV for Training\n",
    "# ============================================\n",
    "df = pd.read_csv(csv_file_train)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df.drop(columns=[\"Vol.\", \"Change %\"], errors=\"ignore\", inplace=True)\n",
    "for col in features:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "    else:\n",
    "        df[col] = df[col].astype(str).str.replace(\",\", \"\", regex=True)\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "df.sort_values(\"Date\", inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"===== TRAINING CSV INFO =====\")\n",
    "print(\"CSV date range:\")\n",
    "print(\"  Min date:\", df[\"Date\"].min())\n",
    "print(\"  Max date:\", df[\"Date\"].max())\n",
    "print(\"Number of rows in df:\", len(df))\n",
    "print(\"Rows that have all features = NaN:\", df[features].isna().all(axis=1).sum())\n",
    "\n",
    "# ============================================\n",
    "# 3. Fit MinMaxScaler on TRAIN only (for original static training)\n",
    "# ============================================\n",
    "df_train_nonan = df[df[\"Date\"] < pd.to_datetime(\"2024-08-01\")].dropna(subset=features)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_train_nonan[features])\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================\n",
    "# 4. Create training sequences\n",
    "# ============================================\n",
    "def make_sequences(df_subset, window=35):\n",
    "    arr = df_subset[features].values\n",
    "    dts = df_subset[\"Date\"].values\n",
    "    X_list, y_list, date_list = [], [], []\n",
    "    for i in range(window, len(arr)):\n",
    "        X_window = arr[i - window: i]\n",
    "        y_target = arr[i]\n",
    "        X_list.append(X_window)\n",
    "        y_list.append(y_target)\n",
    "        date_list.append(dts[i])\n",
    "    return np.array(X_list), np.array(y_list), np.array(date_list)\n",
    "\n",
    "# ============================================\n",
    "# 5. Validation & Prediction Utilities\n",
    "# ============================================\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_type=\"LSTM\", window_width=35):\n",
    "        super().__init__()\n",
    "        self.model_type = model_type\n",
    "        self.window_width = window_width\n",
    "        if model_type == \"CNN\":\n",
    "            self.conv1 = nn.Conv1d(in_channels=4, out_channels=64, kernel_size=3)\n",
    "            self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "            with torch.no_grad():\n",
    "                dummy_input = torch.zeros(1, 4, self.window_width)\n",
    "                dummy_output = self.conv2(F.relu(self.conv1(dummy_input)))\n",
    "                conv_output_size = dummy_output.shape[1] * dummy_output.shape[2]\n",
    "            self.fc = nn.Linear(conv_output_size, 4)\n",
    "        elif model_type == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(input_size=4, hidden_size=128, num_layers=2,\n",
    "                               batch_first=True, dropout=0.1)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "        elif model_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(input_size=4, hidden_size=128, num_layers=2,\n",
    "                              batch_first=True, dropout=0.1)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "        elif model_type == \"RNN\":\n",
    "            self.rnn = nn.RNN(input_size=4, hidden_size=128, num_layers=2,\n",
    "                              batch_first=True, nonlinearity=\"relu\", dropout=0.1)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "        elif model_type == \"EnhancedLSTM\":\n",
    "            self.rnn = nn.LSTM(input_size=4, hidden_size=128, num_layers=3,\n",
    "                               batch_first=True, dropout=0.2)\n",
    "            self.bn = nn.BatchNorm1d(128)\n",
    "            self.dropout = nn.Dropout(0.2)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "        elif model_type == \"Transformer\":\n",
    "            self.input_linear = nn.Linear(4, 128)\n",
    "            encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=8, dropout=0.1)\n",
    "            self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=3)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "        elif model_type == \"N-BEATS\":\n",
    "            self.input_size = window_width * 4\n",
    "            self.blocks = nn.ModuleList([nn.Sequential(\n",
    "                nn.Linear(self.input_size, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 4)\n",
    "            ) for _ in range(3)])\n",
    "        elif model_type == \"N-HITS\":\n",
    "            self.input_size = window_width * 4\n",
    "            self.blocks = nn.ModuleList([nn.Sequential(\n",
    "                nn.Linear(self.input_size, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 4)\n",
    "            ) for _ in range(3)])\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.model_type == \"CNN\":\n",
    "            x = x.permute(0, 2, 1)\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = x.view(x.size(0), -1)\n",
    "            out = self.fc(x)\n",
    "        elif self.model_type in [\"LSTM\", \"GRU\", \"RNN\"]:\n",
    "            out, _ = self.rnn(x)\n",
    "            out = out[:, -1, :]\n",
    "            out = self.fc(out)\n",
    "        elif self.model_type == \"EnhancedLSTM\":\n",
    "            out, _ = self.rnn(x)\n",
    "            out = out[:, -1, :]\n",
    "            out = self.bn(out)\n",
    "            out = self.dropout(out)\n",
    "            out = self.fc(out)\n",
    "        elif self.model_type == \"Transformer\":\n",
    "            x = self.input_linear(x)\n",
    "            x = x.permute(1, 0, 2)\n",
    "            x = self.transformer_encoder(x)\n",
    "            x = x[-1, :, :]\n",
    "            out = self.fc(x)\n",
    "        elif self.model_type in [\"N-BEATS\", \"N-HITS\"]:\n",
    "            x_flat = x.reshape(x.size(0), -1)\n",
    "            forecast = 0\n",
    "            for block in self.blocks:\n",
    "                forecast += block(x_flat)\n",
    "            out = forecast\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type\")\n",
    "        return out\n",
    "\n",
    "def inverse_transform_4cols(y_4, scaler_obj):\n",
    "    return scaler_obj.inverse_transform(y_4)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=150, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "def half_blind_validation_loss(model, df_scaled, val_start, val_end, window=35):\n",
    "    criterion = nn.MSELoss()\n",
    "    df_work = df_scaled.copy()\n",
    "    df_work.sort_values(\"Date\", inplace=True)\n",
    "    val_mask = (df_work[\"Date\"] >= val_start) & (df_work[\"Date\"] <= val_end)\n",
    "    val_dates = np.sort(df_work.loc[val_mask, \"Date\"].unique())\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for d in val_dates:\n",
    "            idx_current = df_work.index[df_work[\"Date\"] == d]\n",
    "            if len(idx_current) == 0:\n",
    "                continue\n",
    "            idx_current = idx_current[0]\n",
    "            start_idx = idx_current - window\n",
    "            if start_idx < 0:\n",
    "                continue\n",
    "            window_df = df_work.iloc[start_idx:idx_current][features].values\n",
    "            if np.isnan(window_df).any():\n",
    "                continue\n",
    "            X_input = torch.tensor(window_df, dtype=torch.float).unsqueeze(0).to(device)\n",
    "            pred_scaled = model(X_input).cpu()[0]\n",
    "            true_vals = df_work.loc[idx_current, features].values.astype(float, copy=False)\n",
    "            if np.isnan(true_vals).any():\n",
    "                continue\n",
    "            loss = criterion(pred_scaled, torch.tensor(true_vals).float())\n",
    "            losses.append(loss.item())\n",
    "    if len(losses) == 0:\n",
    "        return 999999.0\n",
    "    return np.mean(losses)\n",
    "\n",
    "def half_blind_validation_preds_df(model, df_scaled, val_start, val_end, window=35):\n",
    "    df_work = df_scaled.copy()\n",
    "    df_work.sort_values(\"Date\", inplace=True)\n",
    "    val_mask = (df_work[\"Date\"] >= val_start) & (df_work[\"Date\"] <= val_end)\n",
    "    val_dates = np.sort(df_work.loc[val_mask, \"Date\"].unique())\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for d in val_dates:\n",
    "            idx_current = df_work.index[df_work[\"Date\"] == d]\n",
    "            if len(idx_current) == 0:\n",
    "                continue\n",
    "            idx_current = idx_current[0]\n",
    "            start_idx = idx_current - window\n",
    "            if start_idx < 0:\n",
    "                continue\n",
    "            window_df = df_work.iloc[start_idx:idx_current][features].values\n",
    "            if np.isnan(window_df).any():\n",
    "                continue\n",
    "            X_input = torch.tensor(window_df, dtype=torch.float).unsqueeze(0).to(device)\n",
    "            pred_scaled = model(X_input).cpu().numpy()[0]\n",
    "            preds.append((d, *pred_scaled))\n",
    "    pred_df = pd.DataFrame(preds, columns=[\"Date\",\"Pred_Price_scaled\",\"Pred_Open_scaled\",\"Pred_High_scaled\",\"Pred_Low_scaled\"])\n",
    "    pred_df.sort_values(\"Date\", inplace=True)\n",
    "    arr_scaled = pred_df[[\"Pred_Price_scaled\",\"Pred_Open_scaled\",\"Pred_High_scaled\",\"Pred_Low_scaled\"]].values\n",
    "    arr_unscaled = inverse_transform_4cols(arr_scaled, scaler)\n",
    "    pred_df[\"Pred_Price_unscaled\"] = arr_unscaled[:,0]\n",
    "    pred_df[\"Pred_Open_unscaled\"]  = arr_unscaled[:,1]\n",
    "    pred_df[\"Pred_High_unscaled\"]  = arr_unscaled[:,2]\n",
    "    pred_df[\"Pred_Low_unscaled\"]   = arr_unscaled[:,3]\n",
    "    return pred_df\n",
    "\n",
    "def forecast_30_days_from_date(model, df_actual, start_date, window=35, horizon=30, device=torch.device(\"cpu\"), scaler=None):\n",
    "    # Get latest available window before start_date\n",
    "    def get_latest_window(actual_df, current_date, window=35, scaler=None):\n",
    "        mask = actual_df[\"Date\"] < current_date\n",
    "        df_sub = actual_df.loc[mask].copy()\n",
    "        df_sub.sort_values(\"Date\", inplace=True)\n",
    "        if len(df_sub) < window:\n",
    "            return None\n",
    "        df_window = df_sub.iloc[-window:].copy()\n",
    "        df_window[features] = df_window[features].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "        arr = scaler.transform(df_window[features])\n",
    "        return arr\n",
    "    arr_window = get_latest_window(df_actual, start_date, window, scaler)\n",
    "    if arr_window is None:\n",
    "        return pd.DataFrame()\n",
    "    rolling_buffer = np.copy(arr_window)\n",
    "    forecast_records = []\n",
    "    current_date = pd.to_datetime(start_date)\n",
    "    for i in range(horizon):\n",
    "        X_input = torch.tensor(rolling_buffer, dtype=torch.float).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred_scaled = model(X_input).cpu().numpy()[0]\n",
    "        pred_unscaled = scaler.inverse_transform(pred_scaled.reshape(1, -1))[0]\n",
    "        dayx = current_date + pd.Timedelta(days=i)\n",
    "        forecast_records.append({\n",
    "            \"ForecastDate\": dayx,\n",
    "            \"Pred_Price_unscaled\": pred_unscaled[0],\n",
    "            \"Pred_Open_unscaled\":  pred_unscaled[1],\n",
    "            \"Pred_High_unscaled\":  pred_unscaled[2],\n",
    "            \"Pred_Low_unscaled\":   pred_unscaled[3],\n",
    "        })\n",
    "        rolling_buffer = np.vstack((rolling_buffer[1:], pred_scaled.reshape(1, -1)))\n",
    "    return pd.DataFrame(forecast_records)\n",
    "\n",
    "# ============================================\n",
    "# 6. Sklearn Wrapper for non-torch models\n",
    "# ============================================\n",
    "class SklearnWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        arr = x.cpu().numpy().reshape(1, -1)\n",
    "        pred = self.model.predict(arr)\n",
    "        return torch.from_numpy(pred).float().to(x.device)\n",
    "    def eval(self):\n",
    "        pass\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "# ============================================\n",
    "# 7. Walk-forward Test for static prediction (for reference)\n",
    "# ============================================\n",
    "def walk_forward_test(model, df_all_scaled, test_start, window=35):\n",
    "    df_work = df_all_scaled.copy()\n",
    "    df_work.sort_values(\"Date\", inplace=True)\n",
    "    preds = []\n",
    "    test_dates = np.sort(df_work[df_work[\"Date\"] >= test_start][\"Date\"].unique())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for d in test_dates:\n",
    "            idx = df_work.index[df_work[\"Date\"] == d]\n",
    "            if len(idx) == 0:\n",
    "                continue\n",
    "            idx = idx[0]\n",
    "            start_idx = idx - window\n",
    "            if start_idx < 0:\n",
    "                continue\n",
    "            window_df = df_work.iloc[start_idx:idx][features].values\n",
    "            if np.isnan(window_df).any():\n",
    "                continue\n",
    "            X_input = torch.tensor(window_df, dtype=torch.float).unsqueeze(0).to(device)\n",
    "            y_pred_scaled = model(X_input).cpu().numpy()[0]\n",
    "            df_work.loc[idx, features] = y_pred_scaled\n",
    "            preds.append((d, *y_pred_scaled))\n",
    "    pred_df = pd.DataFrame(preds, columns=[\"Date\",\"Pred_Price_scaled\",\"Pred_Open_scaled\",\"Pred_High_scaled\",\"Pred_Low_scaled\"])\n",
    "    arr_scaled = pred_df[[\"Pred_Price_scaled\",\"Pred_Open_scaled\",\"Pred_High_scaled\",\"Pred_Low_scaled\"]].values\n",
    "    arr_unscaled = inverse_transform_4cols(arr_scaled, scaler)\n",
    "    pred_df[\"Pred_Price_unscaled\"] = arr_unscaled[:, 0]\n",
    "    pred_df[\"Pred_Open_unscaled\"]  = arr_unscaled[:, 1]\n",
    "    pred_df[\"Pred_High_unscaled\"]  = arr_unscaled[:, 2]\n",
    "    pred_df[\"Pred_Low_unscaled\"]   = arr_unscaled[:, 3]\n",
    "    return pred_df.sort_values(\"Date\")\n",
    "\n",
    "# ============================================\n",
    "# 8. Plotting Functions (unchanged from your previous code)\n",
    "# ============================================\n",
    "def evaluate_and_plot_all_models(results_dict, df_scaled, df_train, train_cutoff, val_cutoff, test_cutoff):\n",
    "    df_real = df_scaled[[\"Date\",\"Price\",\"Open\",\"High\",\"Low\"]].copy()\n",
    "    df_real.sort_values(\"Date\", inplace=True)\n",
    "    mask_trainval = (df_real[\"Date\"] < test_cutoff)\n",
    "    df_real_plot = df_real.loc[mask_trainval].copy()\n",
    "    arr_scaled = df_real_plot[features].values\n",
    "    arr_unscaled = inverse_transform_4cols(arr_scaled, scaler)\n",
    "    df_real_plot[\"Real_Price_unscaled\"] = arr_unscaled[:, 0]\n",
    "    plt.figure(figsize=(14,7))\n",
    "    plt.plot(df_real_plot[\"Date\"], df_real_plot[\"Real_Price_unscaled\"], color=\"black\", label=\"Actual (Train+Val)\")\n",
    "    merged_df = df_real.copy()\n",
    "    merged_df.sort_values(\"Date\", inplace=True)\n",
    "    color_map = {\n",
    "        \"LSTM\": \"red\",\n",
    "        \"GRU\": \"blue\",\n",
    "        \"RNN\": \"green\",\n",
    "        \"CNN\": \"orange\",\n",
    "        \"EnhancedLSTM\": \"magenta\",\n",
    "        \"Transformer\": \"cyan\",\n",
    "        \"N-BEATS\": \"brown\",\n",
    "        \"N-HITS\": \"pink\",\n",
    "        \"SVM\": \"olive\",\n",
    "        \"GPR\": \"teal\",\n",
    "        \"Boost\": \"purple\"\n",
    "    }\n",
    "    for mname, info in results_dict.items():\n",
    "        val_df = info[\"val_pred_df\"]\n",
    "        test_df = info[\"test_pred_df\"]\n",
    "        frames = []\n",
    "        if val_df is not None:\n",
    "            frames.append(val_df.rename(columns={\"Pred_Price_unscaled\": f\"Pred_{mname}\"}))\n",
    "        if test_df is not None:\n",
    "            frames.append(test_df.rename(columns={\"Pred_Price_unscaled\": f\"Pred_{mname}\"}))\n",
    "        if frames:\n",
    "            comb = pd.concat(frames, ignore_index=True)\n",
    "            comb = comb[[\"Date\", f\"Pred_{mname}\"]].drop_duplicates(\"Date\")\n",
    "            comb.sort_values(\"Date\", inplace=True)\n",
    "            merged_df = pd.merge(merged_df, comb, on=\"Date\", how=\"left\")\n",
    "    for mname in results_dict.keys():\n",
    "        col = f\"Pred_{mname}\"\n",
    "        if col in merged_df.columns:\n",
    "            plt.plot(merged_df[\"Date\"], merged_df[col],\n",
    "                     color=color_map.get(mname, \"gray\"), linestyle=\"-\", label=f\"{mname} Pred\")\n",
    "    plt.axvspan(df_train[\"Date\"].min(), train_cutoff, color=\"skyblue\", alpha=0.1, label=\"Train\")\n",
    "    plt.axvspan(train_cutoff, val_cutoff, color=\"green\", alpha=0.1, label=\"Validation\")\n",
    "    plt.axvspan(test_cutoff, merged_df[\"Date\"].max(), color=\"yellow\", alpha=0.1, label=\"Test\")\n",
    "    plt.title(\"Joint Diagram: Actual Price vs. Predictions (Silver Futures)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price (unscaled)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_moe_vs_actual(df_moe, start_date, end_date):\n",
    "    dfp = df_moe[(df_moe[\"ForecastDate\"] >= start_date) & (df_moe[\"ForecastDate\"] <= end_date)].copy()\n",
    "    if dfp.empty:\n",
    "        print(\"No MoE data in specified window.\")\n",
    "        return\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(dfp[\"ForecastDate\"], dfp[\"ActualPrice\"], color=\"black\", lw=2, label=\"Actual\")\n",
    "    plt.plot(dfp[\"ForecastDate\"], dfp[\"MOE_Pred\"], color=\"red\", lw=2, linestyle=\"--\", label=\"MOE\")\n",
    "    plt.title(\"Mixture-of-Experts vs. Actual (Zoom-In)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compute_confidences_and_top3(final_rolling_fcst, df_actual):\n",
    "    df_pred = final_rolling_fcst[[\"ForecastDate\", \"Model\", \"Pred_Price_unscaled\"]].copy()\n",
    "    df_a = df_actual.rename(columns={\"Date\": \"ForecastDate\", \"Price\": \"ActualPrice\"})\n",
    "    df_merged = pd.merge(df_pred, df_a[[\"ForecastDate\", \"ActualPrice\"]], on=\"ForecastDate\", how=\"inner\")\n",
    "    df_merged.dropna(subset=[\"ActualPrice\", \"Pred_Price_unscaled\"], inplace=True)\n",
    "    df_merged[\"AbsError\"] = (df_merged[\"Pred_Price_unscaled\"] - df_merged[\"ActualPrice\"]).abs()\n",
    "    def group_conf(grp):\n",
    "        err_min = grp[\"AbsError\"].min()\n",
    "        err_max = grp[\"AbsError\"].max()\n",
    "        if abs(err_max - err_min) < 1e-9:\n",
    "            grp[\"Confidence\"] = 1.0\n",
    "        else:\n",
    "            grp[\"Confidence\"] = 1.0 - ((grp[\"AbsError\"] - err_min) / (err_max - err_min))\n",
    "        return grp\n",
    "    df_out = df_merged.groupby(\"ForecastDate\", group_keys=False).apply(group_conf)\n",
    "    unq_days = sorted(df_out[\"ForecastDate\"].unique())\n",
    "    for d in unq_days:\n",
    "        day_grp = df_out[df_out[\"ForecastDate\"] == d].copy()\n",
    "        day_grp.sort_values(\"AbsError\", inplace=True)\n",
    "        top_3 = day_grp.head(3)\n",
    "        print(f\"\\n=== {d.date()} ===\")\n",
    "        for _, row in top_3.iterrows():\n",
    "            print(f\"  Model={row['Model']}, Error={row['AbsError']:.3f}, Conf={row['Confidence']:.3f}\")\n",
    "    return df_out[[\"ForecastDate\", \"Model\", \"Pred_Price_unscaled\", \"AbsError\", \"Confidence\", \"ActualPrice\"]].copy()\n",
    "\n",
    "def produce_moe_predictions(df_conf):\n",
    "    grouped = []\n",
    "    best_model_records = []\n",
    "    for fdate, grp in df_conf.groupby(\"ForecastDate\"):\n",
    "        grp_sorted = grp.sort_values(\"Confidence\", ascending=False).reset_index(drop=True)\n",
    "        top3 = grp_sorted.head(3).copy()\n",
    "        sum_conf = top3[\"Confidence\"].sum()\n",
    "        if abs(sum_conf) < 1e-9:\n",
    "            top3[\"NormConf\"] = 1.0 / 3.0\n",
    "        else:\n",
    "            top3[\"NormConf\"] = top3[\"Confidence\"] / sum_conf\n",
    "        moe_pred = (top3[\"NormConf\"] * top3[\"Pred_Price_unscaled\"]).sum()\n",
    "        actual = grp[\"ActualPrice\"].iloc[0]\n",
    "        moe_abs_err = abs(moe_pred - actual)\n",
    "        best_model = grp_sorted.loc[0, \"Model\"]\n",
    "        best_conf = grp_sorted.loc[0, \"Confidence\"]\n",
    "        best_err = grp_sorted.loc[0, \"AbsError\"]\n",
    "        best_model_records.append({\n",
    "            \"ForecastDate\": fdate,\n",
    "            \"BestModel\": best_model,\n",
    "            \"BestModelConf\": best_conf,\n",
    "            \"BestModelError\": best_err\n",
    "        })\n",
    "        grouped.append({\n",
    "            \"ForecastDate\": fdate,\n",
    "            \"MOE_Pred\": moe_pred,\n",
    "            \"ActualPrice\": actual,\n",
    "            \"MOE_AbsError\": moe_abs_err\n",
    "        })\n",
    "    df_moe = pd.DataFrame(grouped)\n",
    "    df_best = pd.DataFrame(best_model_records)\n",
    "    print(\"\\n===== Best Model of the Day (highest confidence) =====\")\n",
    "    for i, row in df_best.sort_values(\"ForecastDate\").iterrows():\n",
    "        print(f\"{row['ForecastDate'].date()}: {row['BestModel']} (Conf={row['BestModelConf']:.3f}, Error={row['BestModelError']:.3f})\")\n",
    "    return df_moe[[\"ForecastDate\", \"MOE_Pred\", \"ActualPrice\", \"MOE_AbsError\"]]\n",
    "\n",
    "# ============================================\n",
    "# 9. NEW: Rolling Training, Validation & Prediction\n",
    "# ============================================\n",
    "def rolling_train_validate_predict(df, df_complete_all,\n",
    "                                   initial_train_cutoff, initial_val_cutoff,\n",
    "                                   window_size, horizon, all_model_types,\n",
    "                                   best_models_dir, base_start_date, base_end_date):\n",
    "    \"\"\"\n",
    "    For each base prediction date (from base_start_date to base_end_date), this function:\n",
    "      - Shifts the training and validation cutoffs by the appropriate offset.\n",
    "      - Prepares a new rolling training set and fits a new scaler.\n",
    "      - Trains (or loads) each model type and stores the model with a name that includes the base date.\n",
    "      - Forecasts the next 'horizon' days using the newly trained models.\n",
    "    \"\"\"\n",
    "    rolling_results = []\n",
    "    base_dates = pd.date_range(start=base_start_date, end=base_end_date, freq=\"D\")\n",
    "    for base_date in base_dates:\n",
    "        offset = (base_date - pd.to_datetime(base_start_date)).days\n",
    "        new_train_cutoff = initial_train_cutoff + timedelta(days=offset)\n",
    "        new_val_cutoff = initial_val_cutoff + timedelta(days=offset)\n",
    "        # By design, the base_date equals new_val_cutoff + 2 days.\n",
    "        print(f\"\\n=== Rolling Window for Base Date {base_date.date()} ===\")\n",
    "        print(f\"Training cutoff: {new_train_cutoff.date()}, Validation cutoff: {new_val_cutoff.date()}\")\n",
    "        \n",
    "        # Create rolling training and validation sets\n",
    "        df_roll_train = df[df[\"Date\"] < new_train_cutoff].copy()\n",
    "        df_roll_val = df[(df[\"Date\"] >= new_train_cutoff) & (df[\"Date\"] <= new_val_cutoff)].copy()\n",
    "        df_roll_train_nonan = df_roll_train.dropna(subset=features)\n",
    "        if df_roll_train_nonan.empty:\n",
    "            print(\"No valid training rows for this window, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Fit a new scaler on the rolling training data\n",
    "        scaler_roll = MinMaxScaler()\n",
    "        scaler_roll.fit(df_roll_train_nonan[features])\n",
    "        \n",
    "        # Scale the rolling training and validation data\n",
    "        df_roll_train_scaled = df_roll_train.copy()\n",
    "        df_roll_train_scaled.loc[df_roll_train_nonan.index, features] = scaler_roll.transform(df_roll_train_nonan[features])\n",
    "        df_roll_val_scaled = df_roll_val.copy()\n",
    "        df_roll_val_nonan = df_roll_val_scaled.dropna(subset=features)\n",
    "        if not df_roll_val_nonan.empty:\n",
    "            df_roll_val_scaled.loc[df_roll_val_nonan.index, features] = scaler_roll.transform(df_roll_val_nonan[features])\n",
    "        df_roll_scaled = pd.concat([df_roll_train_scaled, df_roll_val_scaled], ignore_index=True)\n",
    "        \n",
    "        # Prepare training sequences from rolling training data\n",
    "        df_roll_train_nonan = df_roll_train_scaled.dropna(subset=features)\n",
    "        X_train_all, y_train_all, _ = make_sequences(df_roll_train_nonan, window=window_size)\n",
    "        if len(X_train_all) == 0:\n",
    "            print(\"Not enough data for training sequences, skipping.\")\n",
    "            continue\n",
    "        X_train_tensor = torch.from_numpy(X_train_all).float()\n",
    "        y_train_tensor = torch.from_numpy(y_train_all).float()\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader_roll = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        # For each model type, train (or load) a model using the rolling training set\n",
    "        models_rolling = {}\n",
    "        for mt in all_model_types:\n",
    "            print(f\"\\n--- Training {mt} for base date {base_date.date()} ---\")\n",
    "            if mt in [\"SVM\", \"GPR\", \"Boost\"]:\n",
    "                best_path = os.path.join(best_models_dir, f\"best_{mt}_{base_date.date()}_Mixture of Experts_V1.pkl\")\n",
    "                if os.path.exists(best_path):\n",
    "                    loaded_model = joblib.load(best_path)\n",
    "                    print(f\"[{mt}] Loaded existing model from {best_path}\")\n",
    "                    models_rolling[mt] = SklearnWrapper(loaded_model)\n",
    "                else:\n",
    "                    if mt == \"SVM\":\n",
    "                        base_model = SVR(kernel='rbf', C=10, epsilon=0.01)\n",
    "                    elif mt == \"GPR\":\n",
    "                        base_model = GaussianProcessRegressor(alpha=1e-2)\n",
    "                    elif mt == \"Boost\":\n",
    "                        base_model = GradientBoostingRegressor(n_estimators=200, max_depth=3)\n",
    "                    else:\n",
    "                        raise ValueError(\"Unsupported sklearn model\")\n",
    "                    multi_model = MultiOutputRegressor(base_model)\n",
    "                    X_train_flat_roll = X_train_all.reshape((X_train_all.shape[0], window_size * 4))\n",
    "                    multi_model.fit(X_train_flat_roll, y_train_all)\n",
    "                    joblib.dump(multi_model, best_path)\n",
    "                    print(f\"[{mt}] Trained and saved model to {best_path}\")\n",
    "                    models_rolling[mt] = SklearnWrapper(multi_model)\n",
    "            else:\n",
    "                best_path = os.path.join(best_models_dir, f\"best_{mt}_{base_date.date()}_Mixture of Experts_V1.pt\")\n",
    "                if os.path.exists(best_path):\n",
    "                    model_obj = BaseModel(mt, window_size).to(device)\n",
    "                    model_obj.load_state_dict(torch.load(best_path, map_location=device))\n",
    "                    print(f\"[{mt}] Loaded existing model from {best_path}\")\n",
    "                    models_rolling[mt] = model_obj\n",
    "                else:\n",
    "                    model_obj = BaseModel(mt, window_size).to(device)\n",
    "                    criterion = nn.MSELoss()\n",
    "                    optimizer = optim.AdamW(model_obj.parameters(), lr=0.005)\n",
    "                    early_stopper = EarlyStopping(patience=150)\n",
    "                    best_loss = float(\"inf\")\n",
    "                    for epoch in range(NUM_EPOCHS):\n",
    "                        model_obj.train()\n",
    "                        epoch_losses = []\n",
    "                        for Xb, yb in train_loader_roll:\n",
    "                            Xb, yb = Xb.to(device), yb.to(device)\n",
    "                            optimizer.zero_grad()\n",
    "                            out = model_obj(Xb)\n",
    "                            loss = criterion(out, yb)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            epoch_losses.append(loss.item())\n",
    "                        val_loss = half_blind_validation_loss(model_obj, df_roll_scaled, new_train_cutoff, new_val_cutoff, window=window_size)\n",
    "                        early_stopper(val_loss)\n",
    "                        if val_loss < best_loss:\n",
    "                            best_loss = val_loss\n",
    "                            torch.save(model_obj.state_dict(), best_path)\n",
    "                        if early_stopper.early_stop:\n",
    "                            print(f\"[{mt}] Early stopping at epoch {epoch+1}\")\n",
    "                            break\n",
    "                    model_obj.load_state_dict(torch.load(best_path, map_location=device))\n",
    "                    print(f\"[{mt}] Completed training for base date {base_date.date()}\")\n",
    "                    models_rolling[mt] = model_obj\n",
    "        \n",
    "        # Now perform forecast using each model\n",
    "        # First, prepare the complete dataset for prediction: sort, fill NaNs, and scale using scaler_roll\n",
    "        df_complete_all_sorted = df_complete_all.copy()\n",
    "        df_complete_all_sorted.sort_values(\"Date\", inplace=True)\n",
    "        df_complete_all_scaled = df_complete_all_sorted.copy()\n",
    "        train_mins = df_roll_train_nonan[features].min()\n",
    "        df_complete_all_scaled[features] = df_complete_all_scaled[features].fillna(train_mins)\n",
    "        df_complete_all_scaled[features] = scaler_roll.transform(df_complete_all_scaled[features])\n",
    "        \n",
    "        for mt, model_obj in models_rolling.items():\n",
    "            df_fcst = forecast_30_days_from_date(\n",
    "                model=model_obj,\n",
    "                df_actual=df_complete_all_scaled,\n",
    "                start_date=str(base_date.date()),\n",
    "                window=window_size,\n",
    "                horizon=horizon,\n",
    "                device=device,\n",
    "                scaler=scaler_roll\n",
    "            )\n",
    "            if df_fcst.empty:\n",
    "                continue\n",
    "            df_fcst[\"BaseDate\"] = base_date\n",
    "            df_fcst[\"Model\"] = mt\n",
    "            rolling_results.append(df_fcst)\n",
    "    if rolling_results:\n",
    "        df_all_fc = pd.concat(rolling_results, ignore_index=True)\n",
    "        df_all_fc.sort_values([\"Model\", \"BaseDate\", \"ForecastDate\"], inplace=True)\n",
    "        df_all_fc.reset_index(drop=True, inplace=True)\n",
    "    else:\n",
    "        df_all_fc = pd.DataFrame()\n",
    "    return df_all_fc\n",
    "\n",
    "# ============================================\n",
    "# 10. MAIN\n",
    "# ============================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Load complete CSV for prediction (rolling test)\n",
    "    df_complete_all = pd.read_csv(csv_file_complete)\n",
    "    df_complete_all[\"Date\"] = pd.to_datetime(df_complete_all[\"Date\"], errors=\"coerce\")\n",
    "    df_complete_all.drop(columns=[\"Vol.\", \"Change %\"], errors=\"ignore\", inplace=True)\n",
    "    for c in features:\n",
    "        df_complete_all[c] = df_complete_all[c].astype(str).str.replace(\",\", \"\", regex=True).astype(float)\n",
    "    df_complete_all.sort_values(\"Date\", inplace=True)\n",
    "    df_complete_all.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Define initial cutoffs (for the first rolling window)\n",
    "    initial_train_cutoff = pd.to_datetime(\"2024-08-01\")\n",
    "    initial_val_cutoff = pd.to_datetime(\"2024-12-31\")\n",
    "    \n",
    "    # Define rolling prediction parameters:\n",
    "    # Base prediction dates from 2025-01-02 to 2025-01-31, with each forecast horizon = 30 days.\n",
    "    base_start_date = \"2025-01-02\"\n",
    "    base_end_date   = \"2025-01-31\"\n",
    "    forecast_horizon = 30\n",
    "    all_model_types = [\"LSTM\", \"GRU\", \"RNN\", \"CNN\", \"Transformer\", \"N-BEATS\", \"N-HITS\", \"SVM\", \"Boost\"]\n",
    "    \n",
    "    # Run the rolling training, validation and forecasting procedure\n",
    "    df_all_fc = rolling_train_validate_predict(df, df_complete_all,\n",
    "                                               initial_train_cutoff, initial_val_cutoff,\n",
    "                                               WINDOW_SIZE, forecast_horizon, all_model_types,\n",
    "                                               best_models_dir, base_start_date, base_end_date)\n",
    "    \n",
    "    print(\"\\n===== ROLLING FORECASTS (Rolling Training + MOE) =====\")\n",
    "    print(df_all_fc.head(50))\n",
    "    print(\"Total rows in rolling forecast:\", len(df_all_fc))\n",
    "    \n",
    "    # Compute confidence and MOE forecasts from the rolling predictions\n",
    "    df_conf = compute_confidences_and_top3(df_all_fc, df_complete_all)\n",
    "    df_moe = produce_moe_predictions(df_conf)\n",
    "    \n",
    "    print(\"\\n===== MOE DataFrame (head) =====\")\n",
    "    print(df_moe.head(20))\n",
    "    plot_moe_vs_actual(df_moe, pd.to_datetime(\"2025-01-01\"), pd.to_datetime(\"2025-01-31\"))\n",
    "    \n",
    "    print(\"\\nAll done with rolling training, validation and prediction.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "import os\n",
    "import random\n",
    "import joblib\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.multioutput import MultiOutputRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor\n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.dates as mdates\n",
    "from datetime import timedelta\n",
    "\n",
    "# 1) SUPPRESS ALL WARNINGS\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=pd.errors.PerformanceWarning)\n",
    "pd.options.mode.chained_assignment = None\n",
    "\n",
    "# ============================================\n",
    "# Global seeds & settings\n",
    "# ============================================\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed_all(0)\n",
    "\n",
    "# Hyperparameters\n",
    "WINDOW_SIZE = 35\n",
    "NUM_EPOCHS  = 100\n",
    "features = [\"Price\", \"Open\", \"High\", \"Low\"]\n",
    "\n",
    "# File paths\n",
    "csv_file_train    = \"Silver Futures Historical Data.csv\"\n",
    "csv_file_complete = \"Silver Futures Historical Data_Complete.csv\"\n",
    "best_models_dir   = \".\"\n",
    "\n",
    "# ============================================\n",
    "# 2. Load & Clean CSV for Training\n",
    "# ============================================\n",
    "df = pd.read_csv(csv_file_train)\n",
    "df[\"Date\"] = pd.to_datetime(df[\"Date\"], errors=\"coerce\")\n",
    "df.drop(columns=[\"Vol.\", \"Change %\"], errors=\"ignore\", inplace=True)\n",
    "for col in features:\n",
    "    if col not in df.columns:\n",
    "        df[col] = np.nan\n",
    "    else:\n",
    "        df[col] = df[col].astype(str).str.replace(\",\", \"\", regex=True)\n",
    "        df[col] = pd.to_numeric(df[col], errors=\"coerce\")\n",
    "df.sort_values(\"Date\", inplace=True)\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "print(\"===== TRAINING CSV INFO =====\")\n",
    "print(\"CSV date range:\")\n",
    "print(\"  Min date:\", df[\"Date\"].min())\n",
    "print(\"  Max date:\", df[\"Date\"].max())\n",
    "print(\"Number of rows in df:\", len(df))\n",
    "print(\"Rows that have all features = NaN:\", df[features].isna().all(axis=1).sum())\n",
    "\n",
    "# ============================================\n",
    "# 3. Fit MinMaxScaler on TRAIN only (for original static training)\n",
    "# ============================================\n",
    "df_train_nonan = df[df[\"Date\"] < pd.to_datetime(\"2024-08-01\")].dropna(subset=features)\n",
    "scaler = MinMaxScaler()\n",
    "scaler.fit(df_train_nonan[features])\n",
    "joblib.dump(scaler, \"scaler.pkl\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# ============================================\n",
    "# 4. Create training sequences\n",
    "# ============================================\n",
    "def make_sequences(df_subset, window=35):\n",
    "    arr = df_subset[features].values\n",
    "    dts = df_subset[\"Date\"].values\n",
    "    X_list, y_list, date_list = [], [], []\n",
    "    for i in range(window, len(arr)):\n",
    "        X_window = arr[i - window: i]\n",
    "        y_target = arr[i]\n",
    "        X_list.append(X_window)\n",
    "        y_list.append(y_target)\n",
    "        date_list.append(dts[i])\n",
    "    return np.array(X_list), np.array(y_list), np.array(date_list)\n",
    "\n",
    "# ============================================\n",
    "# 5. Validation & Prediction Utilities\n",
    "# ============================================\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_type=\"LSTM\", window_width=35):\n",
    "        super().__init__()\n",
    "        self.model_type = model_type\n",
    "        self.window_width = window_width\n",
    "        if model_type == \"CNN\":\n",
    "            self.conv1 = nn.Conv1d(in_channels=4, out_channels=64, kernel_size=3)\n",
    "            self.conv2 = nn.Conv1d(in_channels=64, out_channels=128, kernel_size=3)\n",
    "            with torch.no_grad():\n",
    "                dummy_input = torch.zeros(1, 4, self.window_width)\n",
    "                dummy_output = self.conv2(F.relu(self.conv1(dummy_input)))\n",
    "                conv_output_size = dummy_output.shape[1] * dummy_output.shape[2]\n",
    "            self.fc = nn.Linear(conv_output_size, 4)\n",
    "        elif model_type == \"LSTM\":\n",
    "            self.rnn = nn.LSTM(input_size=4, hidden_size=128, num_layers=2,\n",
    "                               batch_first=True, dropout=0.1)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "        elif model_type == \"GRU\":\n",
    "            self.rnn = nn.GRU(input_size=4, hidden_size=128, num_layers=2,\n",
    "                              batch_first=True, dropout=0.1)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "        elif model_type == \"RNN\":\n",
    "            self.rnn = nn.RNN(input_size=4, hidden_size=128, num_layers=2,\n",
    "                              batch_first=True, nonlinearity=\"relu\", dropout=0.1)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "        elif model_type == \"EnhancedLSTM\":\n",
    "            self.rnn = nn.LSTM(input_size=4, hidden_size=128, num_layers=3,\n",
    "                               batch_first=True, dropout=0.2)\n",
    "            self.bn = nn.BatchNorm1d(128)\n",
    "            self.dropout = nn.Dropout(0.2)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "        elif model_type == \"Transformer\":\n",
    "            self.input_linear = nn.Linear(4, 128)\n",
    "            encoder_layer = nn.TransformerEncoderLayer(d_model=128, nhead=8, dropout=0.1)\n",
    "            self.transformer_encoder = nn.TransformerEncoder(encoder_layer, num_layers=3)\n",
    "            self.fc = nn.Linear(128, 4)\n",
    "        elif model_type == \"N-BEATS\":\n",
    "            self.input_size = window_width * 4\n",
    "            self.blocks = nn.ModuleList([nn.Sequential(\n",
    "                nn.Linear(self.input_size, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 4)\n",
    "            ) for _ in range(3)])\n",
    "        elif model_type == \"N-HITS\":\n",
    "            self.input_size = window_width * 4\n",
    "            self.blocks = nn.ModuleList([nn.Sequential(\n",
    "                nn.Linear(self.input_size, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 128),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(128, 4)\n",
    "            ) for _ in range(3)])\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type\")\n",
    "    \n",
    "    def forward(self, x):\n",
    "        if self.model_type == \"CNN\":\n",
    "            x = x.permute(0, 2, 1)\n",
    "            x = F.relu(self.conv1(x))\n",
    "            x = F.relu(self.conv2(x))\n",
    "            x = x.view(x.size(0), -1)\n",
    "            out = self.fc(x)\n",
    "        elif self.model_type in [\"LSTM\", \"GRU\", \"RNN\"]:\n",
    "            out, _ = self.rnn(x)\n",
    "            out = out[:, -1, :]\n",
    "            out = self.fc(out)\n",
    "        elif self.model_type == \"EnhancedLSTM\":\n",
    "            out, _ = self.rnn(x)\n",
    "            out = out[:, -1, :]\n",
    "            out = self.bn(out)\n",
    "            out = self.dropout(out)\n",
    "            out = self.fc(out)\n",
    "        elif self.model_type == \"Transformer\":\n",
    "            x = self.input_linear(x)\n",
    "            x = x.permute(1, 0, 2)\n",
    "            x = self.transformer_encoder(x)\n",
    "            x = x[-1, :, :]\n",
    "            out = self.fc(x)\n",
    "        elif self.model_type in [\"N-BEATS\", \"N-HITS\"]:\n",
    "            x_flat = x.reshape(x.size(0), -1)\n",
    "            forecast = 0\n",
    "            for block in self.blocks:\n",
    "                forecast += block(x_flat)\n",
    "            out = forecast\n",
    "        else:\n",
    "            raise ValueError(\"Invalid model_type\")\n",
    "        return out\n",
    "\n",
    "def inverse_transform_4cols(y_4, scaler_obj):\n",
    "    return scaler_obj.inverse_transform(y_4)\n",
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=150, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.best_loss = None\n",
    "        self.early_stop = False\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None:\n",
    "            self.best_loss = val_loss\n",
    "        elif val_loss > self.best_loss - self.min_delta:\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                print(\"Early stopping triggered\")\n",
    "                self.early_stop = True\n",
    "        else:\n",
    "            self.best_loss = val_loss\n",
    "            self.counter = 0\n",
    "\n",
    "def half_blind_validation_loss(model, df_scaled, val_start, val_end, window=35):\n",
    "    criterion = nn.MSELoss()\n",
    "    df_work = df_scaled.copy()\n",
    "    df_work.sort_values(\"Date\", inplace=True)\n",
    "    val_mask = (df_work[\"Date\"] >= val_start) & (df_work[\"Date\"] <= val_end)\n",
    "    val_dates = np.sort(df_work.loc[val_mask, \"Date\"].unique())\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    with torch.no_grad():\n",
    "        for d in val_dates:\n",
    "            idx_current = df_work.index[df_work[\"Date\"] == d]\n",
    "            if len(idx_current) == 0:\n",
    "                continue\n",
    "            idx_current = idx_current[0]\n",
    "            start_idx = idx_current - window\n",
    "            if start_idx < 0:\n",
    "                continue\n",
    "            window_df = df_work.iloc[start_idx:idx_current][features].values\n",
    "            if np.isnan(window_df).any():\n",
    "                continue\n",
    "            X_input = torch.tensor(window_df, dtype=torch.float).unsqueeze(0).to(device)\n",
    "            pred_scaled = model(X_input).cpu()[0]\n",
    "            true_vals = df_work.loc[idx_current, features].values.astype(float, copy=False)\n",
    "            if np.isnan(true_vals).any():\n",
    "                continue\n",
    "            loss = criterion(pred_scaled, torch.tensor(true_vals).float())\n",
    "            losses.append(loss.item())\n",
    "    if len(losses) == 0:\n",
    "        return 999999.0\n",
    "    return np.mean(losses)\n",
    "\n",
    "def half_blind_validation_preds_df(model, df_scaled, val_start, val_end, window=35):\n",
    "    df_work = df_scaled.copy()\n",
    "    df_work.sort_values(\"Date\", inplace=True)\n",
    "    val_mask = (df_work[\"Date\"] >= val_start) & (df_work[\"Date\"] <= val_end)\n",
    "    val_dates = np.sort(df_work.loc[val_mask, \"Date\"].unique())\n",
    "    model.eval()\n",
    "    preds = []\n",
    "    with torch.no_grad():\n",
    "        for d in val_dates:\n",
    "            idx_current = df_work.index[df_work[\"Date\"] == d]\n",
    "            if len(idx_current) == 0:\n",
    "                continue\n",
    "            idx_current = idx_current[0]\n",
    "            start_idx = idx_current - window\n",
    "            if start_idx < 0:\n",
    "                continue\n",
    "            window_df = df_work.iloc[start_idx:idx_current][features].values\n",
    "            if np.isnan(window_df).any():\n",
    "                continue\n",
    "            X_input = torch.tensor(window_df, dtype=torch.float).unsqueeze(0).to(device)\n",
    "            pred_scaled = model(X_input).cpu().numpy()[0]\n",
    "            preds.append((d, *pred_scaled))\n",
    "    pred_df = pd.DataFrame(preds, columns=[\"Date\",\"Pred_Price_scaled\",\"Pred_Open_scaled\",\"Pred_High_scaled\",\"Pred_Low_scaled\"])\n",
    "    pred_df.sort_values(\"Date\", inplace=True)\n",
    "    arr_scaled = pred_df[[\"Pred_Price_scaled\",\"Pred_Open_scaled\",\"Pred_High_scaled\",\"Pred_Low_scaled\"]].values\n",
    "    arr_unscaled = inverse_transform_4cols(arr_scaled, scaler)\n",
    "    pred_df[\"Pred_Price_unscaled\"] = arr_unscaled[:,0]\n",
    "    pred_df[\"Pred_Open_unscaled\"]  = arr_unscaled[:,1]\n",
    "    pred_df[\"Pred_High_unscaled\"]  = arr_unscaled[:,2]\n",
    "    pred_df[\"Pred_Low_unscaled\"]   = arr_unscaled[:,3]\n",
    "    return pred_df\n",
    "\n",
    "def forecast_30_days_from_date(model, df_actual, start_date, window=35, horizon=30, device=torch.device(\"cpu\"), scaler=None):\n",
    "    # Get latest available window before start_date\n",
    "    def get_latest_window(actual_df, current_date, window=35, scaler=None):\n",
    "        mask = actual_df[\"Date\"] < current_date\n",
    "        df_sub = actual_df.loc[mask].copy()\n",
    "        df_sub.sort_values(\"Date\", inplace=True)\n",
    "        if len(df_sub) < window:\n",
    "            return None\n",
    "        df_window = df_sub.iloc[-window:].copy()\n",
    "        df_window[features] = df_window[features].fillna(method=\"ffill\").fillna(method=\"bfill\")\n",
    "        arr = scaler.transform(df_window[features])\n",
    "        return arr\n",
    "    arr_window = get_latest_window(df_actual, start_date, window, scaler)\n",
    "    if arr_window is None:\n",
    "        return pd.DataFrame()\n",
    "    rolling_buffer = np.copy(arr_window)\n",
    "    forecast_records = []\n",
    "    current_date = pd.to_datetime(start_date)\n",
    "    for i in range(horizon):\n",
    "        X_input = torch.tensor(rolling_buffer, dtype=torch.float).unsqueeze(0).to(device)\n",
    "        with torch.no_grad():\n",
    "            pred_scaled = model(X_input).cpu().numpy()[0]\n",
    "        pred_unscaled = scaler.inverse_transform(pred_scaled.reshape(1, -1))[0]\n",
    "        dayx = current_date + pd.Timedelta(days=i)\n",
    "        forecast_records.append({\n",
    "            \"ForecastDate\": dayx,\n",
    "            \"Pred_Price_unscaled\": pred_unscaled[0],\n",
    "            \"Pred_Open_unscaled\":  pred_unscaled[1],\n",
    "            \"Pred_High_unscaled\":  pred_unscaled[2],\n",
    "            \"Pred_Low_unscaled\":   pred_unscaled[3],\n",
    "        })\n",
    "        rolling_buffer = np.vstack((rolling_buffer[1:], pred_scaled.reshape(1, -1)))\n",
    "    return pd.DataFrame(forecast_records)\n",
    "\n",
    "# ============================================\n",
    "# 6. Sklearn Wrapper for non-torch models\n",
    "# ============================================\n",
    "class SklearnWrapper:\n",
    "    def __init__(self, model):\n",
    "        self.model = model\n",
    "    def forward(self, x):\n",
    "        arr = x.cpu().numpy().reshape(1, -1)\n",
    "        pred = self.model.predict(arr)\n",
    "        return torch.from_numpy(pred).float().to(x.device)\n",
    "    def eval(self):\n",
    "        pass\n",
    "    def __call__(self, x):\n",
    "        return self.forward(x)\n",
    "\n",
    "# ============================================\n",
    "# 7. Walk-forward Test for static prediction (for reference)\n",
    "# ============================================\n",
    "def walk_forward_test(model, df_all_scaled, test_start, window=35):\n",
    "    df_work = df_all_scaled.copy()\n",
    "    df_work.sort_values(\"Date\", inplace=True)\n",
    "    preds = []\n",
    "    test_dates = np.sort(df_work[df_work[\"Date\"] >= test_start][\"Date\"].unique())\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for d in test_dates:\n",
    "            idx = df_work.index[df_work[\"Date\"] == d]\n",
    "            if len(idx) == 0:\n",
    "                continue\n",
    "            idx = idx[0]\n",
    "            start_idx = idx - window\n",
    "            if start_idx < 0:\n",
    "                continue\n",
    "            window_df = df_work.iloc[start_idx:idx][features].values\n",
    "            if np.isnan(window_df).any():\n",
    "                continue\n",
    "            X_input = torch.tensor(window_df, dtype=torch.float).unsqueeze(0).to(device)\n",
    "            y_pred_scaled = model(X_input).cpu().numpy()[0]\n",
    "            df_work.loc[idx, features] = y_pred_scaled\n",
    "            preds.append((d, *y_pred_scaled))\n",
    "    pred_df = pd.DataFrame(preds, columns=[\"Date\",\"Pred_Price_scaled\",\"Pred_Open_scaled\",\"Pred_High_scaled\",\"Pred_Low_scaled\"])\n",
    "    arr_scaled = pred_df[[\"Pred_Price_scaled\",\"Pred_Open_scaled\",\"Pred_High_scaled\",\"Pred_Low_scaled\"]].values\n",
    "    arr_unscaled = inverse_transform_4cols(arr_scaled, scaler)\n",
    "    pred_df[\"Pred_Price_unscaled\"] = arr_unscaled[:, 0]\n",
    "    pred_df[\"Pred_Open_unscaled\"]  = arr_unscaled[:, 1]\n",
    "    pred_df[\"Pred_High_unscaled\"]  = arr_unscaled[:, 2]\n",
    "    pred_df[\"Pred_Low_unscaled\"]   = arr_unscaled[:, 3]\n",
    "    return pred_df.sort_values(\"Date\")\n",
    "\n",
    "def evaluate_and_plot_all_models(results_dict, df_scaled, df_train, train_cutoff, val_cutoff, test_cutoff):\n",
    "    df_real = df_scaled[[\"Date\",\"Price\",\"Open\",\"High\",\"Low\"]].copy()\n",
    "    df_real.sort_values(\"Date\", inplace=True)\n",
    "    mask_trainval = (df_real[\"Date\"] < test_cutoff)\n",
    "    df_real_plot = df_real.loc[mask_trainval].copy()\n",
    "    arr_scaled = df_real_plot[features].values\n",
    "    arr_unscaled = inverse_transform_4cols(arr_scaled, scaler)\n",
    "    df_real_plot[\"Real_Price_unscaled\"] = arr_unscaled[:, 0]\n",
    "    plt.figure(figsize=(14,7))\n",
    "    plt.plot(df_real_plot[\"Date\"], df_real_plot[\"Real_Price_unscaled\"], color=\"black\", label=\"Actual (Train+Val)\")\n",
    "    merged_df = df_real.copy()\n",
    "    merged_df.sort_values(\"Date\", inplace=True)\n",
    "    color_map = {\n",
    "        \"LSTM\": \"red\",\n",
    "        \"GRU\": \"blue\",\n",
    "        \"RNN\": \"green\",\n",
    "        \"CNN\": \"orange\",\n",
    "        \"EnhancedLSTM\": \"magenta\",\n",
    "        \"Transformer\": \"cyan\",\n",
    "        \"N-BEATS\": \"brown\",\n",
    "        \"N-HITS\": \"pink\",\n",
    "        \"SVM\": \"olive\",\n",
    "        \"GPR\": \"teal\",\n",
    "        \"Boost\": \"purple\"\n",
    "    }\n",
    "    for mname, info in results_dict.items():\n",
    "        val_df = info[\"val_pred_df\"]\n",
    "        test_df = info[\"test_pred_df\"]\n",
    "        frames = []\n",
    "        if val_df is not None:\n",
    "            frames.append(val_df.rename(columns={\"Pred_Price_unscaled\": f\"Pred_{mname}\"}))\n",
    "        if test_df is not None:\n",
    "            frames.append(test_df.rename(columns={\"Pred_Price_unscaled\": f\"Pred_{mname}\"}))\n",
    "        if frames:\n",
    "            comb = pd.concat(frames, ignore_index=True)\n",
    "            comb = comb[[\"Date\", f\"Pred_{mname}\"]].drop_duplicates(\"Date\")\n",
    "            comb.sort_values(\"Date\", inplace=True)\n",
    "            merged_df = pd.merge(merged_df, comb, on=\"Date\", how=\"left\")\n",
    "    for mname in results_dict.keys():\n",
    "        col = f\"Pred_{mname}\"\n",
    "        if col in merged_df.columns:\n",
    "            plt.plot(merged_df[\"Date\"], merged_df[col],\n",
    "                     color=color_map.get(mname, \"gray\"), linestyle=\"-\", label=f\"{mname} Pred\")\n",
    "    plt.axvspan(df_train[\"Date\"].min(), train_cutoff, color=\"skyblue\", alpha=0.1, label=\"Train\")\n",
    "    plt.axvspan(train_cutoff, val_cutoff, color=\"green\", alpha=0.1, label=\"Validation\")\n",
    "    plt.axvspan(test_cutoff, merged_df[\"Date\"].max(), color=\"yellow\", alpha=0.1, label=\"Test\")\n",
    "    plt.title(\"Joint Diagram: Actual Price vs. Predictions (Silver Futures)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price (unscaled)\")\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "def plot_moe_vs_actual(df_moe, start_date, end_date):\n",
    "    dfp = df_moe[(df_moe[\"ForecastDate\"] >= start_date) & (df_moe[\"ForecastDate\"] <= end_date)].copy()\n",
    "    if dfp.empty:\n",
    "        print(\"No MoE data in specified window.\")\n",
    "        return\n",
    "    plt.figure(figsize=(10,5))\n",
    "    plt.plot(dfp[\"ForecastDate\"], dfp[\"ActualPrice\"], color=\"black\", lw=2, label=\"Actual\")\n",
    "    plt.plot(dfp[\"ForecastDate\"], dfp[\"MOE_Pred\"], color=\"red\", lw=2, linestyle=\"--\", label=\"MOE\")\n",
    "    plt.title(\"Mixture-of-Experts vs. Actual (Zoom-In)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"Price\")\n",
    "    plt.grid(True)\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "def compute_confidences_and_top3(final_rolling_fcst, df_actual):\n",
    "    df_pred = final_rolling_fcst[[\"ForecastDate\", \"Model\", \"Pred_Price_unscaled\"]].copy()\n",
    "    df_a = df_actual.rename(columns={\"Date\": \"ForecastDate\", \"Price\": \"ActualPrice\"})\n",
    "    df_merged = pd.merge(df_pred, df_a[[\"ForecastDate\", \"ActualPrice\"]], on=\"ForecastDate\", how=\"inner\")\n",
    "    df_merged.dropna(subset=[\"ActualPrice\", \"Pred_Price_unscaled\"], inplace=True)\n",
    "    df_merged[\"AbsError\"] = (df_merged[\"Pred_Price_unscaled\"] - df_merged[\"ActualPrice\"]).abs()\n",
    "    def group_conf(grp):\n",
    "        err_min = grp[\"AbsError\"].min()\n",
    "        err_max = grp[\"AbsError\"].max()\n",
    "        if abs(err_max - err_min) < 1e-9:\n",
    "            grp[\"Confidence\"] = 1.0\n",
    "        else:\n",
    "            grp[\"Confidence\"] = 1.0 - ((grp[\"AbsError\"] - err_min) / (err_max - err_min))\n",
    "        return grp\n",
    "    df_out = df_merged.groupby(\"ForecastDate\", group_keys=False).apply(group_conf)\n",
    "    unq_days = sorted(df_out[\"ForecastDate\"].unique())\n",
    "    for d in unq_days:\n",
    "        day_grp = df_out[df_out[\"ForecastDate\"] == d].copy()\n",
    "        day_grp.sort_values(\"AbsError\", inplace=True)\n",
    "        top_3 = day_grp.head(3)\n",
    "        print(f\"\\n=== {d.date()} ===\")\n",
    "        for _, row in top_3.iterrows():\n",
    "            print(f\"  Model={row['Model']}, Error={row['AbsError']:.3f}, Conf={row['Confidence']:.3f}\")\n",
    "    return df_out[[\"ForecastDate\", \"Model\", \"Pred_Price_unscaled\", \"AbsError\", \"Confidence\", \"ActualPrice\"]].copy()\n",
    "\n",
    "def produce_moe_predictions(df_conf):\n",
    "    grouped = []\n",
    "    best_model_records = []\n",
    "    for fdate, grp in df_conf.groupby(\"ForecastDate\"):\n",
    "        grp_sorted = grp.sort_values(\"Confidence\", ascending=False).reset_index(drop=True)\n",
    "        top3 = grp_sorted.head(3).copy()\n",
    "        sum_conf = top3[\"Confidence\"].sum()\n",
    "        if abs(sum_conf) < 1e-9:\n",
    "            top3[\"NormConf\"] = 1.0 / 3.0\n",
    "        else:\n",
    "            top3[\"NormConf\"] = top3[\"Confidence\"] / sum_conf\n",
    "        moe_pred = (top3[\"NormConf\"] * top3[\"Pred_Price_unscaled\"]).sum()\n",
    "        actual = grp[\"ActualPrice\"].iloc[0]\n",
    "        moe_abs_err = abs(moe_pred - actual)\n",
    "        best_model = grp_sorted.loc[0, \"Model\"]\n",
    "        best_conf = grp_sorted.loc[0, \"Confidence\"]\n",
    "        best_err = grp_sorted.loc[0, \"AbsError\"]\n",
    "        best_model_records.append({\n",
    "            \"ForecastDate\": fdate,\n",
    "            \"BestModel\": best_model,\n",
    "            \"BestModelConf\": best_conf,\n",
    "            \"BestModelError\": best_err\n",
    "        })\n",
    "        grouped.append({\n",
    "            \"ForecastDate\": fdate,\n",
    "            \"MOE_Pred\": moe_pred,\n",
    "            \"ActualPrice\": actual,\n",
    "            \"MOE_AbsError\": moe_abs_err\n",
    "        })\n",
    "    df_moe = pd.DataFrame(grouped)\n",
    "    df_best = pd.DataFrame(best_model_records)\n",
    "    print(\"\\n===== Best Model of the Day (highest confidence) =====\")\n",
    "    for i, row in df_best.sort_values(\"ForecastDate\").iterrows():\n",
    "        print(f\"{row['ForecastDate'].date()}: {row['BestModel']} (Conf={row['BestModelConf']:.3f}, Error={row['BestModelError']:.3f})\")\n",
    "    return df_moe[[\"ForecastDate\", \"MOE_Pred\", \"ActualPrice\", \"MOE_AbsError\"]]\n",
    "\n",
    "# ============================================\n",
    "# 9. NEW: Rolling Training, Validation & Prediction\n",
    "# ============================================\n",
    "def rolling_train_validate_predict(df, df_complete_all,\n",
    "                                   initial_train_cutoff, initial_val_cutoff,\n",
    "                                   window_size, horizon, all_model_types,\n",
    "                                   best_models_dir, base_start_date, base_end_date):\n",
    "    \"\"\"\n",
    "    For each base prediction date (from base_start_date to base_end_date), this function:\n",
    "      - Shifts the training and validation cutoffs by the appropriate offset.\n",
    "      - Prepares a new rolling training set and fits a new scaler.\n",
    "      - Trains (or loads) each model type and stores the model with a name that includes the base date.\n",
    "      - Forecasts the next 'horizon' days using the newly trained models.\n",
    "    \"\"\"\n",
    "    rolling_results = []\n",
    "    base_dates = pd.date_range(start=base_start_date, end=base_end_date, freq=\"D\")\n",
    "    for base_date in base_dates:\n",
    "        offset = (base_date - pd.to_datetime(base_start_date)).days\n",
    "        new_train_cutoff = initial_train_cutoff + timedelta(days=offset)\n",
    "        new_val_cutoff = initial_val_cutoff + timedelta(days=offset)\n",
    "        # By design, the base_date equals new_val_cutoff + 2 days.\n",
    "        print(f\"\\n=== Rolling Window for Base Date {base_date.date()} ===\")\n",
    "        print(f\"Training cutoff: {new_train_cutoff.date()}, Validation cutoff: {new_val_cutoff.date()}\")\n",
    "        \n",
    "        # Create rolling training and validation sets\n",
    "        df_roll_train = df[df[\"Date\"] < new_train_cutoff].copy()\n",
    "        df_roll_val = df[(df[\"Date\"] >= new_train_cutoff) & (df[\"Date\"] <= new_val_cutoff)].copy()\n",
    "        df_roll_train_nonan = df_roll_train.dropna(subset=features)\n",
    "        if df_roll_train_nonan.empty:\n",
    "            print(\"No valid training rows for this window, skipping.\")\n",
    "            continue\n",
    "        \n",
    "        # Fit a new scaler on the rolling training data\n",
    "        scaler_roll = MinMaxScaler()\n",
    "        scaler_roll.fit(df_roll_train_nonan[features])\n",
    "        \n",
    "        # Scale the rolling training and validation data\n",
    "        df_roll_train_scaled = df_roll_train.copy()\n",
    "        df_roll_train_scaled.loc[df_roll_train_nonan.index, features] = scaler_roll.transform(df_roll_train_nonan[features])\n",
    "        df_roll_val_scaled = df_roll_val.copy()\n",
    "        df_roll_val_nonan = df_roll_val_scaled.dropna(subset=features)\n",
    "        if not df_roll_val_nonan.empty:\n",
    "            df_roll_val_scaled.loc[df_roll_val_nonan.index, features] = scaler_roll.transform(df_roll_val_nonan[features])\n",
    "        df_roll_scaled = pd.concat([df_roll_train_scaled, df_roll_val_scaled], ignore_index=True)\n",
    "        \n",
    "        # Prepare training sequences from rolling training data\n",
    "        df_roll_train_nonan = df_roll_train_scaled.dropna(subset=features)\n",
    "        X_train_all, y_train_all, _ = make_sequences(df_roll_train_nonan, window=window_size)\n",
    "        if len(X_train_all) == 0:\n",
    "            print(\"Not enough data for training sequences, skipping.\")\n",
    "            continue\n",
    "        X_train_tensor = torch.from_numpy(X_train_all).float()\n",
    "        y_train_tensor = torch.from_numpy(y_train_all).float()\n",
    "        train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n",
    "        train_loader_roll = DataLoader(train_dataset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        # For each model type, train (or load) a model using the rolling training set\n",
    "        models_rolling = {}\n",
    "        for mt in all_model_types:\n",
    "            print(f\"\\n--- Training {mt} for base date {base_date.date()} ---\")\n",
    "            if mt in [\"SVM\", \"GPR\", \"Boost\"]:\n",
    "                best_path = os.path.join(best_models_dir, f\"best_{mt}_{base_date.date()}_Mixture of Experts_V1.pkl\")\n",
    "                if os.path.exists(best_path):\n",
    "                    loaded_model = joblib.load(best_path)\n",
    "                    print(f\"[{mt}] Loaded existing model from {best_path}\")\n",
    "                    models_rolling[mt] = SklearnWrapper(loaded_model)\n",
    "                else:\n",
    "                    if mt == \"SVM\":\n",
    "                        base_model = SVR(kernel='rbf', C=10, epsilon=0.01)\n",
    "                    elif mt == \"GPR\":\n",
    "                        base_model = GaussianProcessRegressor(alpha=1e-2)\n",
    "                    elif mt == \"Boost\":\n",
    "                        base_model = GradientBoostingRegressor(n_estimators=200, max_depth=3)\n",
    "                    else:\n",
    "                        raise ValueError(\"Unsupported sklearn model\")\n",
    "                    multi_model = MultiOutputRegressor(base_model)\n",
    "                    X_train_flat_roll = X_train_all.reshape((X_train_all.shape[0], window_size * 4))\n",
    "                    multi_model.fit(X_train_flat_roll, y_train_all)\n",
    "                    joblib.dump(multi_model, best_path)\n",
    "                    print(f\"[{mt}] Trained and saved model to {best_path}\")\n",
    "                    models_rolling[mt] = SklearnWrapper(multi_model)\n",
    "            else:\n",
    "                best_path = os.path.join(best_models_dir, f\"best_{mt}_{base_date.date()}_Mixture of Experts_V1.pt\")\n",
    "                if os.path.exists(best_path):\n",
    "                    model_obj = BaseModel(mt, window_size).to(device)\n",
    "                    model_obj.load_state_dict(torch.load(best_path, map_location=device))\n",
    "                    print(f\"[{mt}] Loaded existing model from {best_path}\")\n",
    "                    models_rolling[mt] = model_obj\n",
    "                else:\n",
    "                    model_obj = BaseModel(mt, window_size).to(device)\n",
    "                    criterion = nn.MSELoss()\n",
    "                    optimizer = optim.AdamW(model_obj.parameters(), lr=0.005)\n",
    "                    early_stopper = EarlyStopping(patience=150)\n",
    "                    best_loss = float(\"inf\")\n",
    "                    for epoch in range(NUM_EPOCHS):\n",
    "                        model_obj.train()\n",
    "                        epoch_losses = []\n",
    "                        for Xb, yb in train_loader_roll:\n",
    "                            Xb, yb = Xb.to(device), yb.to(device)\n",
    "                            optimizer.zero_grad()\n",
    "                            out = model_obj(Xb)\n",
    "                            loss = criterion(out, yb)\n",
    "                            loss.backward()\n",
    "                            optimizer.step()\n",
    "                            epoch_losses.append(loss.item())\n",
    "                        val_loss = half_blind_validation_loss(model_obj, df_roll_scaled, new_train_cutoff, new_val_cutoff, window=window_size)\n",
    "                        early_stopper(val_loss)\n",
    "                        if val_loss < best_loss:\n",
    "                            best_loss = val_loss\n",
    "                            torch.save(model_obj.state_dict(), best_path)\n",
    "                        if early_stopper.early_stop:\n",
    "                            print(f\"[{mt}] Early stopping at epoch {epoch+1}\")\n",
    "                            break\n",
    "                    model_obj.load_state_dict(torch.load(best_path, map_location=device))\n",
    "                    print(f\"[{mt}] Completed training for base date {base_date.date()}\")\n",
    "                    models_rolling[mt] = model_obj\n",
    "        \n",
    "        # Now perform forecast using each model\n",
    "        # Prepare complete dataset for prediction: sort, fill NaNs, and scale using scaler_roll\n",
    "        df_complete_all_sorted = df_complete_all.copy()\n",
    "        df_complete_all_sorted.sort_values(\"Date\", inplace=True)\n",
    "        df_complete_all_scaled = df_complete_all_sorted.copy()\n",
    "        train_mins = df_roll_train_nonan[features].min()\n",
    "        df_complete_all_scaled[features] = df_complete_all_scaled[features].fillna(train_mins)\n",
    "        df_complete_all_scaled[features] = scaler_roll.transform(df_complete_all_scaled[features])\n",
    "        \n",
    "        for mt, model_obj in models_rolling.items():\n",
    "            df_fcst = forecast_30_days_from_date(\n",
    "                model=model_obj,\n",
    "                df_actual=df_complete_all_scaled,\n",
    "                start_date=str(base_date.date()),\n",
    "                window=window_size,\n",
    "                horizon=horizon,\n",
    "                device=device,\n",
    "                scaler=scaler_roll\n",
    "            )\n",
    "            if df_fcst.empty:\n",
    "                continue\n",
    "            df_fcst[\"BaseDate\"] = base_date\n",
    "            df_fcst[\"Model\"] = mt\n",
    "            rolling_results.append(df_fcst)\n",
    "    if rolling_results:\n",
    "        df_all_fc = pd.concat(rolling_results, ignore_index=True)\n",
    "        df_all_fc.sort_values([\"Model\", \"BaseDate\", \"ForecastDate\"], inplace=True)\n",
    "        df_all_fc.reset_index(drop=True, inplace=True)\n",
    "    else:\n",
    "        df_all_fc = pd.DataFrame()\n",
    "    return df_all_fc\n",
    "\n",
    "# ========================================================\n",
    "# NEW PLOTTING FUNCTIONS FOR DAILY & CONCATENATED DIAGRAMS\n",
    "# ========================================================\n",
    "\n",
    "def plot_daily_diagrams_by_model(day_i, horizon_days, daily_fcst_dict, df_actual):\n",
    "    \"\"\"\n",
    "    For a given base (forecast) day, this function loops through each model's daily forecast (in daily_fcst_dict)\n",
    "    and produces:\n",
    "      - A Joint Diagram: Actual prices vs. that model's forecast for [day_i, day_i+horizon_days]\n",
    "      - A Zoom-In Diagram: A closer view of the same.\n",
    "    \"\"\"\n",
    "    for m, df_fc in daily_fcst_dict.items():\n",
    "        day_end = day_i + pd.Timedelta(days=horizon_days)\n",
    "        # Filter forecast for this model for the day\n",
    "        df_model_fc = df_fc[(df_fc[\"ForecastDate\"] >= day_i) & (df_fc[\"ForecastDate\"] <= day_end)]\n",
    "        # Filter actual data for the same range (assuming df_actual has a \"Date\" column and \"Price\")\n",
    "        df_actual_range = df_actual[(df_actual[\"Date\"] >= day_i) & (df_actual[\"Date\"] <= day_end)]\n",
    "        # Joint Diagram\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.plot(df_actual_range[\"Date\"], df_actual_range[\"Price\"], color=\"black\", label=\"Actual Price\")\n",
    "        plt.plot(df_model_fc[\"ForecastDate\"], df_model_fc[\"Pred_Price_unscaled\"], linestyle=\"--\", label=f\"{m} Forecast\")\n",
    "        plt.title(f\"Daily Joint Diagram for {m} on {day_i.date()}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price (unscaled)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        # Zoom-In Diagram\n",
    "        plt.figure(figsize=(12,5))\n",
    "        plt.plot(df_actual_range[\"Date\"], df_actual_range[\"Price\"], color=\"black\", label=\"Actual Price\")\n",
    "        plt.plot(df_model_fc[\"ForecastDate\"], df_model_fc[\"Pred_Price_unscaled\"], linestyle=\"--\", label=f\"{m} Forecast\")\n",
    "        plt.title(f\"Daily Zoom-In Diagram for {m} on {day_i.date()}\")\n",
    "        plt.xlabel(\"Date\")\n",
    "        plt.ylabel(\"Price (unscaled)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "def plot_concatenated_joint_diagrams_by_model(df_all_fc):\n",
    "    \"\"\"\n",
    "    For each model in df_all_fc (the final rolling forecast DataFrame),\n",
    "    this function produces a single figure that concatenates all forecast curves.\n",
    "    \"\"\"\n",
    "    models = df_all_fc[\"Model\"].unique()\n",
    "    for m in models:\n",
    "        df_model = df_all_fc[df_all_fc[\"Model\"] == m].copy()\n",
    "        plt.figure(figsize=(12,6))\n",
    "        plt.plot(df_model[\"ForecastDate\"], df_model[\"Pred_Price_unscaled\"], linestyle=\"--\", marker=\"o\", label=f\"{m} Forecast\")\n",
    "        plt.title(f\"Concatenated Joint Diagram for {m}\")\n",
    "        plt.xlabel(\"Forecast Date\")\n",
    "        plt.ylabel(\"Predicted Price (unscaled)\")\n",
    "        plt.legend()\n",
    "        plt.grid(True)\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "# ============================================\n",
    "# 10. MAIN\n",
    "# ============================================\n",
    "if __name__ == \"__main__\":\n",
    "    # Load complete CSV for prediction (rolling test)\n",
    "    df_complete_all = pd.read_csv(csv_file_complete)\n",
    "    df_complete_all[\"Date\"] = pd.to_datetime(df_complete_all[\"Date\"], errors=\"coerce\")\n",
    "    df_complete_all.drop(columns=[\"Vol.\", \"Change %\"], errors=\"ignore\", inplace=True)\n",
    "    for c in features:\n",
    "        df_complete_all[c] = df_complete_all[c].astype(str).str.replace(\",\", \"\", regex=True).astype(float)\n",
    "    df_complete_all.sort_values(\"Date\", inplace=True)\n",
    "    df_complete_all.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    # Define initial cutoffs (for the first rolling window)\n",
    "    initial_train_cutoff = pd.to_datetime(\"2024-08-01\")\n",
    "    initial_val_cutoff = pd.to_datetime(\"2024-12-31\")\n",
    "    \n",
    "    # Define rolling prediction parameters:\n",
    "    # Base prediction dates from 2025-01-02 to 2025-01-31, with each forecast horizon = 30 days.\n",
    "    base_start_date = \"2025-01-02\"\n",
    "    base_end_date   = \"2025-01-31\"\n",
    "    forecast_horizon = 30\n",
    "    all_model_types = [\"LSTM\", \"GRU\", \"RNN\", \"CNN\", \"Transformer\", \"N-BEATS\", \"N-HITS\", \"SVM\", \"Boost\"]\n",
    "    \n",
    "    # Run the rolling training, validation and forecasting procedure\n",
    "    df_all_fc = rolling_train_validate_predict(df, df_complete_all,\n",
    "                                               initial_train_cutoff, initial_val_cutoff,\n",
    "                                               WINDOW_SIZE, forecast_horizon, all_model_types,\n",
    "                                               best_models_dir, base_start_date, base_end_date)\n",
    "    \n",
    "    print(\"\\n===== ROLLING FORECASTS (Rolling Training + MOE) =====\")\n",
    "    print(df_all_fc.head(50))\n",
    "    print(\"Total rows in rolling forecast:\", len(df_all_fc))\n",
    "    \n",
    "    # Compute confidence and MOE forecasts from the rolling predictions\n",
    "    df_conf = compute_confidences_and_top3(df_all_fc, df_complete_all)\n",
    "    df_moe = produce_moe_predictions(df_conf)\n",
    "    \n",
    "    print(\"\\n===== MOE DataFrame (head) =====\")\n",
    "    print(df_moe.head(20))\n",
    "    plot_moe_vs_actual(df_moe, pd.to_datetime(\"2025-01-01\"), pd.to_datetime(\"2025-01-31\"))\n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # NEW: For each rolling (base) day, produce daily diagrams per model\n",
    "    # ------------------------------------------\n",
    "    unique_base_dates = df_all_fc[\"BaseDate\"].unique()\n",
    "    for bd in unique_base_dates:\n",
    "        df_day = df_all_fc[df_all_fc[\"BaseDate\"] == bd]\n",
    "        # Create a dictionary keyed by model name for this base day\n",
    "        daily_fcst_dict = {}\n",
    "        for m in df_day[\"Model\"].unique():\n",
    "            daily_fcst_dict[m] = df_day[df_day[\"Model\"] == m]\n",
    "        # Plot daily joint & zoom-in diagrams for each model on this base date\n",
    "        plot_daily_diagrams_by_model(pd.to_datetime(bd), forecast_horizon, daily_fcst_dict, df_complete_all)\n",
    "    \n",
    "    # ------------------------------------------\n",
    "    # NEW: Plot concatenated joint diagram for each model across all base dates\n",
    "    # ------------------------------------------\n",
    "    plot_concatenated_joint_diagrams_by_model(df_all_fc)\n",
    "    \n",
    "    print(\"\\nAll done with rolling training, validation, prediction and plotting.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
